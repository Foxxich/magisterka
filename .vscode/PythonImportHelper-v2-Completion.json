[
    {
        "label": "Sequential",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "Sequential",
        "importPath": "tensorflow.keras.models",
        "description": "tensorflow.keras.models",
        "isExtraImport": true,
        "detail": "tensorflow.keras.models",
        "documentation": {}
    },
    {
        "label": "Dense",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Dropout",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "BatchNormalization",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "LeakyReLU",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Input",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Embedding",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "LSTM",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Bidirectional",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Dense",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Dropout",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "GlobalAveragePooling1D",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Dense",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Dropout",
        "importPath": "tensorflow.keras.layers",
        "description": "tensorflow.keras.layers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.layers",
        "documentation": {}
    },
    {
        "label": "Adam",
        "importPath": "tensorflow.keras.optimizers",
        "description": "tensorflow.keras.optimizers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.optimizers",
        "documentation": {}
    },
    {
        "label": "Adam",
        "importPath": "tensorflow.keras.optimizers",
        "description": "tensorflow.keras.optimizers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.optimizers",
        "documentation": {}
    },
    {
        "label": "ReduceLROnPlateau",
        "importPath": "tensorflow.keras.callbacks",
        "description": "tensorflow.keras.callbacks",
        "isExtraImport": true,
        "detail": "tensorflow.keras.callbacks",
        "documentation": {}
    },
    {
        "label": "EarlyStopping",
        "importPath": "tensorflow.keras.callbacks",
        "description": "tensorflow.keras.callbacks",
        "isExtraImport": true,
        "detail": "tensorflow.keras.callbacks",
        "documentation": {}
    },
    {
        "label": "l2",
        "importPath": "tensorflow.keras.regularizers",
        "description": "tensorflow.keras.regularizers",
        "isExtraImport": true,
        "detail": "tensorflow.keras.regularizers",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "VotingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "AdaBoostClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "VotingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "GradientBoostingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "StackingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "AdaBoostClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "StackingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "GradientBoostingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "GradientBoostingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "BaggingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "AdaBoostClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "VotingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "AdaBoostClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "VotingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "VotingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "BaggingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "AdaBoostClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "VotingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "RandomForestClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "GradientBoostingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "VotingClassifier",
        "importPath": "sklearn.ensemble",
        "description": "sklearn.ensemble",
        "isExtraImport": true,
        "detail": "sklearn.ensemble",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "MLPClassifier",
        "importPath": "sklearn.neural_network",
        "description": "sklearn.neural_network",
        "isExtraImport": true,
        "detail": "sklearn.neural_network",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "LogisticRegression",
        "importPath": "sklearn.linear_model",
        "description": "sklearn.linear_model",
        "isExtraImport": true,
        "detail": "sklearn.linear_model",
        "documentation": {}
    },
    {
        "label": "xgboost",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "xgboost",
        "description": "xgboost",
        "detail": "xgboost",
        "documentation": {}
    },
    {
        "label": "XGBClassifier",
        "importPath": "xgboost",
        "description": "xgboost",
        "isExtraImport": true,
        "detail": "xgboost",
        "documentation": {}
    },
    {
        "label": "XGBClassifier",
        "importPath": "xgboost",
        "description": "xgboost",
        "isExtraImport": true,
        "detail": "xgboost",
        "documentation": {}
    },
    {
        "label": "XGBClassifier",
        "importPath": "xgboost",
        "description": "xgboost",
        "isExtraImport": true,
        "detail": "xgboost",
        "documentation": {}
    },
    {
        "label": "XGBClassifier",
        "importPath": "xgboost",
        "description": "xgboost",
        "isExtraImport": true,
        "detail": "xgboost",
        "documentation": {}
    },
    {
        "label": "SelectKBest",
        "importPath": "sklearn.feature_selection",
        "description": "sklearn.feature_selection",
        "isExtraImport": true,
        "detail": "sklearn.feature_selection",
        "documentation": {}
    },
    {
        "label": "chi2",
        "importPath": "sklearn.feature_selection",
        "description": "sklearn.feature_selection",
        "isExtraImport": true,
        "detail": "sklearn.feature_selection",
        "documentation": {}
    },
    {
        "label": "MinMaxScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "StandardScaler",
        "importPath": "sklearn.preprocessing",
        "description": "sklearn.preprocessing",
        "isExtraImport": true,
        "detail": "sklearn.preprocessing",
        "documentation": {}
    },
    {
        "label": "CatBoostClassifier",
        "importPath": "catboost",
        "description": "catboost",
        "isExtraImport": true,
        "detail": "catboost",
        "documentation": {}
    },
    {
        "label": "CatBoostClassifier",
        "importPath": "catboost",
        "description": "catboost",
        "isExtraImport": true,
        "detail": "catboost",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "precision_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "recall_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "f1_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "classification_report",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "accuracy_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "cohen_kappa_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "f1_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "log_loss",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "matthews_corrcoef",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "precision_recall_curve",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "precision_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "recall_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "roc_auc_score",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "auc",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "auc",
        "importPath": "sklearn.metrics",
        "description": "sklearn.metrics",
        "isExtraImport": true,
        "detail": "sklearn.metrics",
        "documentation": {}
    },
    {
        "label": "SMOTETomek",
        "importPath": "imblearn.combine",
        "description": "imblearn.combine",
        "isExtraImport": true,
        "detail": "imblearn.combine",
        "documentation": {}
    },
    {
        "label": "re",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "re",
        "description": "re",
        "detail": "re",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SVC",
        "importPath": "sklearn.svm",
        "description": "sklearn.svm",
        "isExtraImport": true,
        "detail": "sklearn.svm",
        "documentation": {}
    },
    {
        "label": "SnowballStemmer",
        "importPath": "nltk.stem",
        "description": "nltk.stem",
        "isExtraImport": true,
        "detail": "nltk.stem",
        "documentation": {}
    },
    {
        "label": "Tokenizer",
        "importPath": "tensorflow.keras.preprocessing.text",
        "description": "tensorflow.keras.preprocessing.text",
        "isExtraImport": true,
        "detail": "tensorflow.keras.preprocessing.text",
        "documentation": {}
    },
    {
        "label": "pad_sequences",
        "importPath": "tensorflow.keras.preprocessing.sequence",
        "description": "tensorflow.keras.preprocessing.sequence",
        "isExtraImport": true,
        "detail": "tensorflow.keras.preprocessing.sequence",
        "documentation": {}
    },
    {
        "label": "cross_val_predict",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_score",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "train_test_split",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "StratifiedKFold",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "cross_val_predict",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "GridSearchCV",
        "importPath": "sklearn.model_selection",
        "description": "sklearn.model_selection",
        "isExtraImport": true,
        "detail": "sklearn.model_selection",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "MultinomialNB",
        "importPath": "sklearn.naive_bayes",
        "description": "sklearn.naive_bayes",
        "isExtraImport": true,
        "detail": "sklearn.naive_bayes",
        "documentation": {}
    },
    {
        "label": "DecisionTreeClassifier",
        "importPath": "sklearn.tree",
        "description": "sklearn.tree",
        "isExtraImport": true,
        "detail": "sklearn.tree",
        "documentation": {}
    },
    {
        "label": "Model",
        "importPath": "keras.models",
        "description": "keras.models",
        "isExtraImport": true,
        "detail": "keras.models",
        "documentation": {}
    },
    {
        "label": "Input",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "LSTM",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "Bidirectional",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "Conv1D",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "MaxPooling1D",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "Flatten",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "Dense",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "concatenate",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "Embedding",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "Reshape",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "ZeroPadding1D",
        "importPath": "keras.layers",
        "description": "keras.layers",
        "isExtraImport": true,
        "detail": "keras.layers",
        "documentation": {}
    },
    {
        "label": "Adadelta",
        "importPath": "keras.optimizers",
        "description": "keras.optimizers",
        "isExtraImport": true,
        "detail": "keras.optimizers",
        "documentation": {}
    },
    {
        "label": "pad_sequences",
        "importPath": "keras.utils",
        "description": "keras.utils",
        "isExtraImport": true,
        "detail": "keras.utils",
        "documentation": {}
    },
    {
        "label": "BertTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "TFBertModel",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "BertTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "RobertaTokenizer",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "TFBertForSequenceClassification",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "TFRobertaForSequenceClassification",
        "importPath": "transformers",
        "description": "transformers",
        "isExtraImport": true,
        "detail": "transformers",
        "documentation": {}
    },
    {
        "label": "defaultdict",
        "importPath": "collections",
        "description": "collections",
        "isExtraImport": true,
        "detail": "collections",
        "documentation": {}
    },
    {
        "label": "KerasClassifier",
        "importPath": "scikeras.wrappers",
        "description": "scikeras.wrappers",
        "isExtraImport": true,
        "detail": "scikeras.wrappers",
        "documentation": {}
    },
    {
        "label": "KNeighborsClassifier",
        "importPath": "sklearn.neighbors",
        "description": "sklearn.neighbors",
        "isExtraImport": true,
        "detail": "sklearn.neighbors",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "random",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "random",
        "description": "random",
        "detail": "random",
        "documentation": {}
    },
    {
        "label": "csv",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "csv",
        "description": "csv",
        "detail": "csv",
        "documentation": {}
    },
    {
        "label": "matplotlib.pyplot",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib.pyplot",
        "description": "matplotlib.pyplot",
        "detail": "matplotlib.pyplot",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "SentenceTransformer",
        "importPath": "sentence_transformers",
        "description": "sentence_transformers",
        "isExtraImport": true,
        "detail": "sentence_transformers",
        "documentation": {}
    },
    {
        "label": "TfidfVectorizer",
        "importPath": "sklearn.feature_extraction.text",
        "description": "sklearn.feature_extraction.text",
        "isExtraImport": true,
        "detail": "sklearn.feature_extraction.text",
        "documentation": {}
    },
    {
        "label": "shutil",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "shutil",
        "description": "shutil",
        "detail": "shutil",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "evaluate_model",
        "importPath": "common",
        "description": "common",
        "isExtraImport": true,
        "detail": "common",
        "documentation": {}
    },
    {
        "label": "get_bert_embeddings",
        "importPath": "common",
        "description": "common",
        "isExtraImport": true,
        "detail": "common",
        "documentation": {}
    },
    {
        "label": "get_roberta_embeddings",
        "importPath": "common",
        "description": "common",
        "isExtraImport": true,
        "detail": "common",
        "documentation": {}
    },
    {
        "label": "load_and_preprocess_data",
        "importPath": "common",
        "description": "common",
        "isExtraImport": true,
        "detail": "common",
        "documentation": {}
    },
    {
        "label": "split_data",
        "importPath": "common",
        "description": "common",
        "isExtraImport": true,
        "detail": "common",
        "documentation": {}
    },
    {
        "label": "split_data_few_shot",
        "importPath": "common",
        "description": "common",
        "isExtraImport": true,
        "detail": "common",
        "documentation": {}
    },
    {
        "label": "split_data_one_shot",
        "importPath": "common",
        "description": "common",
        "isExtraImport": true,
        "detail": "common",
        "documentation": {}
    },
    {
        "label": "get_transformer_embeddings",
        "importPath": "common",
        "description": "common",
        "isExtraImport": true,
        "detail": "common",
        "documentation": {}
    },
    {
        "label": "metoda1",
        "importPath": "run1",
        "description": "run1",
        "isExtraImport": true,
        "detail": "run1",
        "documentation": {}
    },
    {
        "label": "metoda2",
        "importPath": "run2",
        "description": "run2",
        "isExtraImport": true,
        "detail": "run2",
        "documentation": {}
    },
    {
        "label": "metoda3",
        "importPath": "run3",
        "description": "run3",
        "isExtraImport": true,
        "detail": "run3",
        "documentation": {}
    },
    {
        "label": "metoda4",
        "importPath": "run4",
        "description": "run4",
        "isExtraImport": true,
        "detail": "run4",
        "documentation": {}
    },
    {
        "label": "metoda5",
        "importPath": "run5",
        "description": "run5",
        "isExtraImport": true,
        "detail": "run5",
        "documentation": {}
    },
    {
        "label": "metoda6",
        "importPath": "run6",
        "description": "run6",
        "isExtraImport": true,
        "detail": "run6",
        "documentation": {}
    },
    {
        "label": "metoda7",
        "importPath": "run7",
        "description": "run7",
        "isExtraImport": true,
        "detail": "run7",
        "documentation": {}
    },
    {
        "label": "metoda8",
        "importPath": "run8",
        "description": "run8",
        "isExtraImport": true,
        "detail": "run8",
        "documentation": {}
    },
    {
        "label": "metoda9",
        "importPath": "run9",
        "description": "run9",
        "isExtraImport": true,
        "detail": "run9",
        "documentation": {}
    },
    {
        "label": "metoda10",
        "importPath": "run10",
        "description": "run10",
        "isExtraImport": true,
        "detail": "run10",
        "documentation": {}
    },
    {
        "label": "metoda11",
        "importPath": "run11",
        "description": "run11",
        "isExtraImport": true,
        "detail": "run11",
        "documentation": {}
    },
    {
        "label": "metoda12",
        "importPath": "run12",
        "description": "run12",
        "isExtraImport": true,
        "detail": "run12",
        "documentation": {}
    },
    {
        "label": "metoda13",
        "importPath": "run13",
        "description": "run13",
        "isExtraImport": true,
        "detail": "run13",
        "documentation": {}
    },
    {
        "label": "metoda14",
        "importPath": "run14",
        "description": "run14",
        "isExtraImport": true,
        "detail": "run14",
        "documentation": {}
    },
    {
        "label": "metoda15",
        "importPath": "run15",
        "description": "run15",
        "isExtraImport": true,
        "detail": "run15",
        "documentation": {}
    },
    {
        "label": "metoda16",
        "importPath": "run16",
        "description": "run16",
        "isExtraImport": true,
        "detail": "run16",
        "documentation": {}
    },
    {
        "label": "metoda17",
        "importPath": "my_run",
        "description": "my_run",
        "isExtraImport": true,
        "detail": "my_run",
        "documentation": {}
    },
    {
        "label": "metoda18",
        "importPath": "my_run",
        "description": "my_run",
        "isExtraImport": true,
        "detail": "my_run",
        "documentation": {}
    },
    {
        "label": "metoda19",
        "importPath": "my_run",
        "description": "my_run",
        "isExtraImport": true,
        "detail": "my_run",
        "documentation": {}
    },
    {
        "label": "metoda20",
        "importPath": "my_run",
        "description": "my_run",
        "isExtraImport": true,
        "detail": "my_run",
        "documentation": {}
    },
    {
        "label": "load_dotenv",
        "importPath": "dotenv",
        "description": "dotenv",
        "isExtraImport": true,
        "detail": "dotenv",
        "documentation": {}
    },
    {
        "label": "scipy.stats",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scipy.stats",
        "description": "scipy.stats",
        "detail": "scipy.stats",
        "documentation": {}
    },
    {
        "label": "matplotlib",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "matplotlib",
        "description": "matplotlib",
        "detail": "matplotlib",
        "documentation": {}
    },
    {
        "label": "Pipeline",
        "importPath": "sklearn.pipeline",
        "description": "sklearn.pipeline",
        "isExtraImport": true,
        "detail": "sklearn.pipeline",
        "documentation": {}
    },
    {
        "label": "LGBMClassifier",
        "importPath": "lightgbm",
        "description": "lightgbm",
        "isExtraImport": true,
        "detail": "lightgbm",
        "documentation": {}
    },
    {
        "label": "imread",
        "importPath": "matplotlib.image",
        "description": "matplotlib.image",
        "isExtraImport": true,
        "detail": "matplotlib.image",
        "documentation": {}
    },
    {
        "label": "imread",
        "importPath": "matplotlib.image",
        "description": "matplotlib.image",
        "isExtraImport": true,
        "detail": "matplotlib.image",
        "documentation": {}
    },
    {
        "label": "GridSpec",
        "importPath": "matplotlib.gridspec",
        "description": "matplotlib.gridspec",
        "isExtraImport": true,
        "detail": "matplotlib.gridspec",
        "documentation": {}
    },
    {
        "label": "create_model",
        "kind": 2,
        "importPath": "article1.run1",
        "description": "article1.run1",
        "peekOfCode": "def create_model(input_dim, units1=128, units2=64, units3=32, dropout_rate=0.2, learning_rate=0.001, l2_reg=0.01):\n    \"\"\"\n    Tworzy model sieci neuronowej z podanymi hiperparametrami.\n    \"\"\"\n    model = Sequential([\n        Dense(units1, input_dim=input_dim, activation=None, kernel_regularizer=l2(l2_reg)),\n        BatchNormalization(),\n        LeakyReLU(alpha=0.1),\n        Dropout(dropout_rate),\n        Dense(units2, activation=None, kernel_regularizer=l2(l2_reg)),",
        "detail": "article1.run1",
        "documentation": {}
    },
    {
        "label": "metoda1",
        "kind": 2,
        "importPath": "article1.run1",
        "description": "article1.run1",
        "peekOfCode": "def metoda1(X_train, y_train, X_test, y_test, n_models=5):\n    \"\"\"\n    Trenuje ensemble modeli neuronowych z różnymi hiperparametrami.\n    Parameters:\n        X_train (np.ndarray): Dane treningowe.\n        y_train (np.ndarray): Etykiety treningowe.\n        X_test (np.ndarray): Dane testowe.\n        y_test (np.ndarray): Etykiety testowe.\n        n_models (int): Liczba modeli w ensemble.\n    Returns:",
        "detail": "article1.run1",
        "documentation": {}
    },
    {
        "label": "metoda10",
        "kind": 2,
        "importPath": "article10.run10",
        "description": "article10.run10",
        "peekOfCode": "def metoda10(X_train, y_train, X_test, y_test):\n    \"\"\"\n    Trenuje model zespołowy z miękkim głosowaniem (soft-voting) i ocenia jego wyniki.\n    Parametry:\n        X_train (np.ndarray): Cechy zbioru treningowego.\n        y_train (lista lub np.ndarray): Etykiety zbioru treningowego.\n        X_test (np.ndarray): Cechy zbioru testowego.\n        y_test (lista lub np.ndarray): Etykiety zbioru testowego.\n    Zwraca:\n        voting_clf: Wytrenowany model VotingClassifier.",
        "detail": "article10.run10",
        "documentation": {}
    },
    {
        "label": "metoda11",
        "kind": 2,
        "importPath": "article11.run11",
        "description": "article11.run11",
        "peekOfCode": "def metoda11(X_train, y_train, X_test, y_test):\n    \"\"\"\n    Trenuje model zespołowy z wykorzystaniem VotingClassifier (Random Forest, Logistic Regression i AdaBoost),\n    stosując selekcję cech, normalizację i miękkie głosowanie.\n    Parametry:\n        X_train (np.ndarray): Cechy zbioru treningowego.\n        y_train (lista lub np.ndarray): Etykiety zbioru treningowego.\n        X_test (np.ndarray): Cechy zbioru testowego.\n        y_test (lista lub np.ndarray): Etykiety zbioru testowego.\n    Zwraca:",
        "detail": "article11.run11",
        "documentation": {}
    },
    {
        "label": "metoda12",
        "kind": 2,
        "importPath": "article12.run12",
        "description": "article12.run12",
        "peekOfCode": "def metoda12(X_train, y_train, X_test, y_test):\n    \"\"\"\n    Trenuje i ocenia klasyfikatory Random Forest oraz CatBoost.\n    Parametry:\n        X_train (array-like): Cechy zbioru treningowego.\n        y_train (array-like): Etykiety zbioru treningowego.\n        X_test (array-like): Cechy zbioru testowego.\n        y_test (array-like): Etykiety zbioru testowego.\n    Zwraca:\n        dict: Słownik zawierający wytrenowane modele oraz odpowiadające ",
        "detail": "article12.run12",
        "documentation": {}
    },
    {
        "label": "metoda13",
        "kind": 2,
        "importPath": "article13.run13",
        "description": "article13.run13",
        "peekOfCode": "def metoda13(X_train, y_train, X_test, y_test):\n    \"\"\"\n    Trenuje model zespołowy (stacking) do obsługi problemu niezrównoważonych klas.\n    Parametry:\n        X_train (np.ndarray): Macierz cech dla danych treningowych.\n        y_train (np.ndarray): Wektor etykiet dla danych treningowych.\n        X_test (np.ndarray): Macierz cech dla danych testowych.\n        y_test (np.ndarray): Wektor etykiet dla danych testowych.\n    Zwraca:\n        StackingClassifier: Wytrenowany model zespołowy typu stacking.",
        "detail": "article13.run13",
        "documentation": {}
    },
    {
        "label": "preprocess_text",
        "kind": 2,
        "importPath": "article14.run14",
        "description": "article14.run14",
        "peekOfCode": "def preprocess_text(text):\n    \"\"\"\n    Oczyszcza i przetwarza tekst poprzez usunięcie URL-i, znaków specjalnych, pojedynczych liter i liczb,\n    oraz stosuje stemming przy użyciu Snowball Stemmer.\n    \"\"\"\n    snowball_stemmer = SnowballStemmer('english')\n    text = re.sub(r'http\\S+', '', text)  # Usuwanie URL-i\n    text = re.sub(r'\\W', ' ', text)  # Usuwanie znaków specjalnych\n    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)  # Usuwanie pojedynczych liter\n    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)  # Usuwanie pojedynczych liter na początku",
        "detail": "article14.run14",
        "documentation": {}
    },
    {
        "label": "metoda14",
        "kind": 2,
        "importPath": "article14.run14",
        "description": "article14.run14",
        "peekOfCode": "def metoda14(X_train, y_train, X_test, y_test):\n    \"\"\"\n    Trenuje model zespołowy stacking z użyciem Random Forest, AdaBoost, SVC i Logistic Regression\n    jako finalnego estymatora.\n    Parametry:\n        X_train (numpy.ndarray): Cechy zbioru treningowego.\n        y_train (numpy.ndarray): Etykiety zbioru treningowego.\n        X_test (numpy.ndarray): Cechy zbioru testowego.\n        y_test (numpy.ndarray): Etykiety zbioru testowego.\n    Zwraca:",
        "detail": "article14.run14",
        "documentation": {}
    },
    {
        "label": "metoda15",
        "kind": 2,
        "importPath": "article15.run15",
        "description": "article15.run15",
        "peekOfCode": "def metoda15(X_train, y_train, X_test, y_test, embedding_dim=200, maxlen=256, epochs=5, batch_size=32):\n    \"\"\"\n    Funkcja trenuje zespół modeli Bi-LSTM z tokenizowanymi i wyściełanymi sekwencjami wejściowymi.\n    Parametry:\n        X_train (list, np.ndarray lub pd.Series): Dane tekstowe do trenowania.\n        y_train (array-like): Etykiety docelowe dla danych treningowych.\n        X_test (list, np.ndarray lub pd.Series): Dane tekstowe do testowania.\n        y_test (array-like): Etykiety docelowe dla danych testowych.\n        embedding_dim (int): Wymiar osadzania (domyślnie: 200).\n        maxlen (int): Maksymalna długość sekwencji wejściowych (domyślnie: 256).",
        "detail": "article15.run15",
        "documentation": {}
    },
    {
        "label": "preprocess_text",
        "kind": 2,
        "importPath": "article16.run16",
        "description": "article16.run16",
        "peekOfCode": "def preprocess_text(X):\n    \"\"\"\n    Niestandardowe przetwarzanie tekstu: konwersja do małych liter, usuwanie stop-słów i zastosowanie stemmingu.\n    \"\"\"\n    from nltk.corpus import stopwords\n    from nltk.stem import SnowballStemmer\n    import re\n    stop_words = set(stopwords.words(\"english\"))\n    stemmer = SnowballStemmer(\"english\")\n    def clean_text(text):",
        "detail": "article16.run16",
        "documentation": {}
    },
    {
        "label": "metoda16",
        "kind": 2,
        "importPath": "article16.run16",
        "description": "article16.run16",
        "peekOfCode": "def metoda16(X_train, y_train, X_test, y_test):\n    \"\"\"\n    Trenuje model zespołowy stacking z meta-klasyfikatorem używającym regresji logistycznej.\n    Parametry:\n        X_train (np.ndarray): Cechy zbioru treningowego.\n        y_train (np.ndarray): Etykiety zbioru treningowego.\n        X_test (np.ndarray): Cechy zbioru testowego.\n        y_test (np.ndarray): Etykiety zbioru testowego.\n    Zwraca:\n        meta_model: Wytrenowany meta-klasyfikator (stacking).",
        "detail": "article16.run16",
        "documentation": {}
    },
    {
        "label": "metoda2",
        "kind": 2,
        "importPath": "article2.run2",
        "description": "article2.run2",
        "peekOfCode": "def metoda2(X_train, y_train, X_test, y_test):\n    \"\"\"\n    Trenuje model wykorzystując GradientBoosting oraz MLP na oddzielnych podzbiorach cech \n    i łączy je za pomocą Regresji Logistycznej.\n    Parametry:\n        X_train (np.ndarray lub DataFrame): Zbiór cech do trenowania.\n        y_train (list lub np.ndarray): Etykiety zbioru treningowego.\n        X_test (np.ndarray lub DataFrame): Zbiór cech do testowania.\n        y_test (list lub np.ndarray): Etykiety zbioru testowego.\n    Zwraca:",
        "detail": "article2.run2",
        "documentation": {}
    },
    {
        "label": "metoda3",
        "kind": 2,
        "importPath": "article3.run3",
        "description": "article3.run3",
        "peekOfCode": "def metoda3(X_train, y_train, X_test, y_test):\n    \"\"\"\n    Trenuje dwupoziomowy model zespołowy wykorzystujący klasyfikatory cechowe i meta-klasyfikatory.\n    Parametry:\n        X_train (np.ndarray): Cechy zbioru treningowego.\n        y_train (list lub np.ndarray): Etykiety zbioru treningowego.\n        X_test (np.ndarray): Cechy zbioru testowego.\n        y_test (list lub np.ndarray): Etykiety zbioru testowego.\n    Zwraca:\n        voting_clf_2: Wytrenowany model zespołowy drugiego poziomu.",
        "detail": "article3.run3",
        "documentation": {}
    },
    {
        "label": "metoda4",
        "kind": 2,
        "importPath": "article4.run4",
        "description": "article4.run4",
        "peekOfCode": "def metoda4(X_train, y_train, X_test, y_test, embedding_dim=100):\n    \"\"\"\n    Trenuje architekturę opartą na zespole sieci Bi-LSTM, CNN i MLP.\n    Zachowuje oryginalną sygnaturę metody, ale modyfikuje wnętrze.\n    Argumenty:\n        X_train (np.ndarray): Zbiór cech do trenowania.\n        y_train (list lub np.ndarray): Etykiety zbioru treningowego.\n        X_test (np.ndarray): Zbiór cech testowych.\n        y_test (list lub np.ndarray): Etykiety zbioru testowego.\n        embedding_dim (int): Rozmiar wymiaru osadzeń (domyślnie: 100).",
        "detail": "article4.run4",
        "documentation": {}
    },
    {
        "label": "metoda5",
        "kind": 2,
        "importPath": "article5.run5",
        "description": "article5.run5",
        "peekOfCode": "def metoda5(X_train, y_train, X_test, y_test):\n    \"\"\"Trenuje model stacking z użyciem Random Forest i XGBoost jako bazowych oraz Logistic Regression jako meta-modelu.\"\"\"\n    # Trenuj modele bazowe: RandomForest i XGBoost\n    rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n    xgb_clf = xgb.XGBClassifier(n_estimators=100, eval_metric='logloss', random_state=42)\n    rf_clf.fit(X_train, y_train)\n    xgb_clf.fit(X_train, y_train)\n    # Uzyskaj predykcje dla zbioru treningowego, aby stworzyć cechy dla meta-modelu\n    rf_preds_train = rf_clf.predict_proba(X_train)[:, 1]\n    xgb_preds_train = xgb_clf.predict_proba(X_train)[:, 1]",
        "detail": "article5.run5",
        "documentation": {}
    },
    {
        "label": "metoda6",
        "kind": 2,
        "importPath": "article6.run6",
        "description": "article6.run6",
        "peekOfCode": "def metoda6(X_train, y_train, X_test, y_test, batch_size=32, use_bert_embeddings=False):\n    \"\"\"\n    Trenuje klasyfikator zespołowy Voting Classifier z wykorzystaniem AdaBoost i Logistic Regression oraz osadzeń BERT.\n    Parametry:\n        X_train (np.ndarray lub lista): Cechy zbioru treningowego lub oryginalne dane tekstowe.\n        y_train (lista): Etykiety zbioru treningowego.\n        X_test (np.ndarray lub lista): Cechy zbioru testowego lub oryginalne dane tekstowe.\n        y_test (lista): Etykiety zbioru testowego.\n        batch_size (int): Rozmiar batcha do generowania osadzeń (domyślnie: 32).\n        use_bert_embeddings (bool): Czy generować osadzenia BERT z surowych danych tekstowych.",
        "detail": "article6.run6",
        "documentation": {}
    },
    {
        "label": "monte_carlo_dropout_inference",
        "kind": 2,
        "importPath": "article7.run7",
        "description": "article7.run7",
        "peekOfCode": "def monte_carlo_dropout_inference(model, data, num_samples=50):\n    \"\"\"\n    Symuluje MC-Dropout poprzez wielokrotne próbkowanie predykcji z różnych podzbiorów drzew.\n    \"\"\"\n    predictions = []\n    n_trees = len(model.estimators_)  # Liczba drzew w lesie\n    for _ in range(num_samples):\n        # Wybierz losowy podzbiór drzew\n        sampled_trees = np.random.choice(model.estimators_, size=int(n_trees * 0.8), replace=False)\n        # Oblicz predykcje z wybranego podzbioru drzew",
        "detail": "article7.run7",
        "documentation": {}
    },
    {
        "label": "compute_meta_attribute_probabilities",
        "kind": 2,
        "importPath": "article7.run7",
        "description": "article7.run7",
        "peekOfCode": "def compute_meta_attribute_probabilities(df, attribute_col, label_col):\n    attribute_probs = defaultdict(lambda: {'real': 0, 'fake': 0})\n    for _, row in df.iterrows():\n        attr_value = row[attribute_col]\n        label = row[label_col]\n        if label == 1:  # Wiadomość \"prawdziwa\"\n            attribute_probs[attr_value]['real'] += 1\n        elif label == 0:  # Wiadomość \"fałszywa\"\n            attribute_probs[attr_value]['fake'] += 1\n    for attr_value, counts in attribute_probs.items():",
        "detail": "article7.run7",
        "documentation": {}
    },
    {
        "label": "heuristic_post_processing",
        "kind": 2,
        "importPath": "article7.run7",
        "description": "article7.run7",
        "peekOfCode": "def heuristic_post_processing(predictions, attribute_probs, attributes, threshold=0.9):\n    final_predictions = []\n    for i, pred in enumerate(predictions):\n        attr_value = attributes[i]\n        if attr_value in attribute_probs:\n            real_prob = attribute_probs[attr_value]['real']\n            fake_prob = attribute_probs[attr_value]['fake']\n            if real_prob > threshold and real_prob > fake_prob:\n                final_predictions.append(1)\n            elif fake_prob > threshold and fake_prob > real_prob:",
        "detail": "article7.run7",
        "documentation": {}
    },
    {
        "label": "metoda7",
        "kind": 2,
        "importPath": "article7.run7",
        "description": "article7.run7",
        "peekOfCode": "def metoda7(X_train, y_train, X_test, y_test):\n    \"\"\"\n    Trenuje Random Forest z symulowanym MC-Dropout i heurystyczną obróbką post-procesową.\n    Zwraca:\n        model: Wytrenowany RandomForestClassifier.\n        X_test: Oryginalne cechy zbioru testowego.\n        y_test: Etykiety zbioru testowego.\n    \"\"\"\n    # Konwersja danych wejściowych do tablic NumPy\n    train_embeddings = X_train.to_numpy() if isinstance(X_train, pd.DataFrame) else np.array(X_train)",
        "detail": "article7.run7",
        "documentation": {}
    },
    {
        "label": "create_dbn_model",
        "kind": 2,
        "importPath": "article8.run8",
        "description": "article8.run8",
        "peekOfCode": "def create_dbn_model(input_dim, num_classes):\n    \"\"\"\n    Tworzy model DBN jako prostą głęboką sieć neuronową z Keras.\n    \"\"\"\n    model = Sequential()\n    model.add(Dense(256, input_dim=input_dim, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(64, activation='relu'))",
        "detail": "article8.run8",
        "documentation": {}
    },
    {
        "label": "metoda8",
        "kind": 2,
        "importPath": "article8.run8",
        "description": "article8.run8",
        "peekOfCode": "def metoda8(X_train, y_train, X_test, y_test):\n    \"\"\"\n    Trenuje klasyfikator zespołowy Voting Classifier z użyciem RandomForest, XGBoost\n    Parametry:\n        X_train (np.ndarray): Cechy zbioru treningowego.\n        y_train (lista lub np.ndarray): Etykiety zbioru treningowego.\n        X_test (np.ndarray): Cechy zbioru testowego.\n        y_test (lista lub np.ndarray): Etykiety zbioru testowego.\n    Zwraca:\n        ensemble_model: Wytrenowany klasyfikator zespołowy.",
        "detail": "article8.run8",
        "documentation": {}
    },
    {
        "label": "metoda9",
        "kind": 2,
        "importPath": "article9.run9",
        "description": "article9.run9",
        "peekOfCode": "def metoda9(X_train, y_train, X_test, y_test):\n    \"\"\"\n    Trenuje różne modele zespołowe i ocenia ich wyniki.\n    Parametry:\n        X_train (np.ndarray): Cechy zbioru treningowego.\n        y_train (lista lub np.ndarray): Etykiety zbioru treningowego.\n        X_test (np.ndarray): Cechy zbioru testowego.\n        y_test (lista lub np.ndarray): Etykiety zbioru testowego.\n    Zwraca:\n        voting: Najlepszy model (VotingClassifier).",
        "detail": "article9.run9",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "datasets.BuzzFeed_dataset.archive.formatter",
        "description": "datasets.BuzzFeed_dataset.archive.formatter",
        "peekOfCode": "df = pd.read_csv(\"C:\\\\Users\\\\Vadym\\\\Documents\\\\magisterka\\\\datasets\\\\BuzzFeed_dataset\\\\BuzzFeed_real_news.csv\", on_bad_lines='skip')\n# Remove empty lines\ndf = df.dropna(how='all')\n# Create new DataFrame with transformed columns\nnew_df = pd.DataFrame({\n    'title': df['title'],\n    'text': df['text'],\n    'subject': df['meta_data'],\n    'date': df['publish_date']\n})",
        "detail": "datasets.BuzzFeed_dataset.archive.formatter",
        "documentation": {}
    },
    {
        "label": "df",
        "kind": 5,
        "importPath": "datasets.BuzzFeed_dataset.archive.formatter",
        "description": "datasets.BuzzFeed_dataset.archive.formatter",
        "peekOfCode": "df = df.dropna(how='all')\n# Create new DataFrame with transformed columns\nnew_df = pd.DataFrame({\n    'title': df['title'],\n    'text': df['text'],\n    'subject': df['meta_data'],\n    'date': df['publish_date']\n})\n# Save to new CSV\nnew_df.to_csv(\"C:\\\\Users\\\\Vadym\\\\Documents\\\\magisterka\\\\datasets\\\\BuzzFeed_dataset\\\\True.csv\", index=False)",
        "detail": "datasets.BuzzFeed_dataset.archive.formatter",
        "documentation": {}
    },
    {
        "label": "new_df",
        "kind": 5,
        "importPath": "datasets.BuzzFeed_dataset.archive.formatter",
        "description": "datasets.BuzzFeed_dataset.archive.formatter",
        "peekOfCode": "new_df = pd.DataFrame({\n    'title': df['title'],\n    'text': df['text'],\n    'subject': df['meta_data'],\n    'date': df['publish_date']\n})\n# Save to new CSV\nnew_df.to_csv(\"C:\\\\Users\\\\Vadym\\\\Documents\\\\magisterka\\\\datasets\\\\BuzzFeed_dataset\\\\True.csv\", index=False)",
        "detail": "datasets.BuzzFeed_dataset.archive.formatter",
        "documentation": {}
    },
    {
        "label": "generate_random_date",
        "kind": 2,
        "importPath": "datasets.WELFake_dataset.archive.optimizer",
        "description": "datasets.WELFake_dataset.archive.optimizer",
        "peekOfCode": "def generate_random_date(start_date, end_date):\n    time_delta = end_date - start_date\n    random_days = random.randrange(time_delta.days)\n    return start_date + timedelta(days=random_days)\ndef process_csv(input_file, output_folder):\n    # Define date range for random dates (last 2 years from today)\n    end_date = datetime(2025, 4, 25)\n    start_date = end_date - timedelta(days=730)  # 2 years back\n    # Read CSV, skip empty lines\n    df = pd.read_csv(input_file, delimiter=',', skip_blank_lines=True)",
        "detail": "datasets.WELFake_dataset.archive.optimizer",
        "documentation": {}
    },
    {
        "label": "process_csv",
        "kind": 2,
        "importPath": "datasets.WELFake_dataset.archive.optimizer",
        "description": "datasets.WELFake_dataset.archive.optimizer",
        "peekOfCode": "def process_csv(input_file, output_folder):\n    # Define date range for random dates (last 2 years from today)\n    end_date = datetime(2025, 4, 25)\n    start_date = end_date - timedelta(days=730)  # 2 years back\n    # Read CSV, skip empty lines\n    df = pd.read_csv(input_file, delimiter=',', skip_blank_lines=True)\n    # Create output folder if it doesn't exist\n    os.makedirs(output_folder, exist_ok=True)\n    # Initialize lists to collect rows for True and Fake\n    true_rows = []",
        "detail": "datasets.WELFake_dataset.archive.optimizer",
        "documentation": {}
    },
    {
        "label": "remove_empty_and_comma_start_lines_csv",
        "kind": 2,
        "importPath": "datasets.WELFake_dataset.archive.remove_empty",
        "description": "datasets.WELFake_dataset.archive.remove_empty",
        "peekOfCode": "def remove_empty_and_comma_start_lines_csv(input_file, output_file):\n    # Expected number of fields (id, title, text, label)\n    expected_fields = 4\n    # Read the raw CSV file content\n    with open(input_file, 'r', encoding='utf-8') as file:\n        lines = file.readlines()\n    # Filter lines:\n    # - Not empty\n    # - Don't start with a comma\n    # - Have exactly the expected number of fields",
        "detail": "datasets.WELFake_dataset.archive.remove_empty",
        "documentation": {}
    },
    {
        "label": "remove_outliers",
        "kind": 2,
        "importPath": "all_plots",
        "description": "all_plots",
        "peekOfCode": "def remove_outliers(data, column):\n    \"\"\"\n    Usuwa wartości znacznie odbiegające od zakresu międzykwartylowego (IQR).\n    \"\"\"\n    Q1 = data[column].quantile(0.25)  # Pierwszy kwartyl (25 percentyl)\n    Q3 = data[column].quantile(0.75)  # Trzeci kwartyl (75 percentyl)\n    IQR = Q3 - Q1  # Rozstęp międzykwartylowy\n    lower_bound = Q1 - 1.5 * IQR  # Dolna granica\n    upper_bound = Q3 + 1.5 * IQR  # Górna granica\n    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]",
        "detail": "all_plots",
        "documentation": {}
    },
    {
        "label": "project_root",
        "kind": 5,
        "importPath": "all_plots",
        "description": "all_plots",
        "peekOfCode": "project_root = os.getcwd()\nbase_folder = os.path.join(project_root)\nplot_base_folder = os.path.join(project_root, \"plots\")\n# Typy folderów do przetworzenia\nfolder_types = ['classic', 'few_shot', 'one_shot']\nfolders = [f\"results_{i}_{ft}\" for ft in folder_types for i in range(1, 4)]\n# Wzorce uruchamiania\nruns_standard = [i for i in range(2, 17) if i != 12]  # Standardowe uruchomienia (2-16, bez 12)\nruns_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Uruchomienia 1-1 do 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Warianty uruchomienia 12",
        "detail": "all_plots",
        "documentation": {}
    },
    {
        "label": "base_folder",
        "kind": 5,
        "importPath": "all_plots",
        "description": "all_plots",
        "peekOfCode": "base_folder = os.path.join(project_root)\nplot_base_folder = os.path.join(project_root, \"plots\")\n# Typy folderów do przetworzenia\nfolder_types = ['classic', 'few_shot', 'one_shot']\nfolders = [f\"results_{i}_{ft}\" for ft in folder_types for i in range(1, 4)]\n# Wzorce uruchamiania\nruns_standard = [i for i in range(2, 17) if i != 12]  # Standardowe uruchomienia (2-16, bez 12)\nruns_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Uruchomienia 1-1 do 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Warianty uruchomienia 12\nruns_highlight = [17, 18, 19, 20, 21]  # Uruchomienia do wyróżnienia na czerwono",
        "detail": "all_plots",
        "documentation": {}
    },
    {
        "label": "plot_base_folder",
        "kind": 5,
        "importPath": "all_plots",
        "description": "all_plots",
        "peekOfCode": "plot_base_folder = os.path.join(project_root, \"plots\")\n# Typy folderów do przetworzenia\nfolder_types = ['classic', 'few_shot', 'one_shot']\nfolders = [f\"results_{i}_{ft}\" for ft in folder_types for i in range(1, 4)]\n# Wzorce uruchamiania\nruns_standard = [i for i in range(2, 17) if i != 12]  # Standardowe uruchomienia (2-16, bez 12)\nruns_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Uruchomienia 1-1 do 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Warianty uruchomienia 12\nruns_highlight = [17, 18, 19, 20, 21]  # Uruchomienia do wyróżnienia na czerwono\n# Kolumny do wczytania",
        "detail": "all_plots",
        "documentation": {}
    },
    {
        "label": "folder_types",
        "kind": 5,
        "importPath": "all_plots",
        "description": "all_plots",
        "peekOfCode": "folder_types = ['classic', 'few_shot', 'one_shot']\nfolders = [f\"results_{i}_{ft}\" for ft in folder_types for i in range(1, 4)]\n# Wzorce uruchamiania\nruns_standard = [i for i in range(2, 17) if i != 12]  # Standardowe uruchomienia (2-16, bez 12)\nruns_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Uruchomienia 1-1 do 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Warianty uruchomienia 12\nruns_highlight = [17, 18, 19, 20, 21]  # Uruchomienia do wyróżnienia na czerwono\n# Kolumny do wczytania\ncolumns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",",
        "detail": "all_plots",
        "documentation": {}
    },
    {
        "label": "folders",
        "kind": 5,
        "importPath": "all_plots",
        "description": "all_plots",
        "peekOfCode": "folders = [f\"results_{i}_{ft}\" for ft in folder_types for i in range(1, 4)]\n# Wzorce uruchamiania\nruns_standard = [i for i in range(2, 17) if i != 12]  # Standardowe uruchomienia (2-16, bez 12)\nruns_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Uruchomienia 1-1 do 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Warianty uruchomienia 12\nruns_highlight = [17, 18, 19, 20, 21]  # Uruchomienia do wyróżnienia na czerwono\n# Kolumny do wczytania\ncolumns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\"",
        "detail": "all_plots",
        "documentation": {}
    },
    {
        "label": "runs_standard",
        "kind": 5,
        "importPath": "all_plots",
        "description": "all_plots",
        "peekOfCode": "runs_standard = [i for i in range(2, 17) if i != 12]  # Standardowe uruchomienia (2-16, bez 12)\nruns_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Uruchomienia 1-1 do 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Warianty uruchomienia 12\nruns_highlight = [17, 18, 19, 20, 21]  # Uruchomienia do wyróżnienia na czerwono\n# Kolumny do wczytania\ncolumns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\"\n]\nfor folder in folders:",
        "detail": "all_plots",
        "documentation": {}
    },
    {
        "label": "runs_1_x",
        "kind": 5,
        "importPath": "all_plots",
        "description": "all_plots",
        "peekOfCode": "runs_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Uruchomienia 1-1 do 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Warianty uruchomienia 12\nruns_highlight = [17, 18, 19, 20, 21]  # Uruchomienia do wyróżnienia na czerwono\n# Kolumny do wczytania\ncolumns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\"\n]\nfor folder in folders:\n    folder_path = os.path.join(base_folder, folder) + '\\\\'",
        "detail": "all_plots",
        "documentation": {}
    },
    {
        "label": "run12_variants",
        "kind": 5,
        "importPath": "all_plots",
        "description": "all_plots",
        "peekOfCode": "run12_variants = [\"12-catboost\", \"12-rf\"]  # Warianty uruchomienia 12\nruns_highlight = [17, 18, 19, 20, 21]  # Uruchomienia do wyróżnienia na czerwono\n# Kolumny do wczytania\ncolumns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\"\n]\nfor folder in folders:\n    folder_path = os.path.join(base_folder, folder) + '\\\\'\n    plots_output_path = os.path.join(plot_base_folder, folder) + '\\\\'",
        "detail": "all_plots",
        "documentation": {}
    },
    {
        "label": "runs_highlight",
        "kind": 5,
        "importPath": "all_plots",
        "description": "all_plots",
        "peekOfCode": "runs_highlight = [17, 18, 19, 20, 21]  # Uruchomienia do wyróżnienia na czerwono\n# Kolumny do wczytania\ncolumns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\"\n]\nfor folder in folders:\n    folder_path = os.path.join(base_folder, folder) + '\\\\'\n    plots_output_path = os.path.join(plot_base_folder, folder) + '\\\\'\n    os.makedirs(plots_output_path, exist_ok=True)  # Tworzy główny folder, jeśli nie istnieje",
        "detail": "all_plots",
        "documentation": {}
    },
    {
        "label": "columns_to_load",
        "kind": 5,
        "importPath": "all_plots",
        "description": "all_plots",
        "peekOfCode": "columns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\"\n]\nfor folder in folders:\n    folder_path = os.path.join(base_folder, folder) + '\\\\'\n    plots_output_path = os.path.join(plot_base_folder, folder) + '\\\\'\n    os.makedirs(plots_output_path, exist_ok=True)  # Tworzy główny folder, jeśli nie istnieje\n    # Tworzenie podfolderów dla zestawów danych\n    datasets = ['BuzzFeed', 'ISOT', 'WELFake']",
        "detail": "all_plots",
        "documentation": {}
    },
    {
        "label": "project_root",
        "kind": 5,
        "importPath": "all_stats",
        "description": "all_stats",
        "peekOfCode": "project_root = os.getcwd()\nbase_folder = os.path.join(project_root)\noutput_base_folder = r\"C:\\Users\\Vadym\\Documents\\magisterka\\output3\"\n# Typy folderów do przetworzenia\nfolder_types = ['classic', 'few_shot', 'one_shot']\nfolders = [f\"results_{i}_{ft}\" for ft in folder_types for i in range(1, 4)]\n# Wzorce uruchamiania\nruns_standard = [i for i in range(2, 17) if i != 12]  # Standardowe uruchomienia (2-16, bez 12)\nruns_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Uruchomienia 1-1 do 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Warianty uruchomienia 12",
        "detail": "all_stats",
        "documentation": {}
    },
    {
        "label": "base_folder",
        "kind": 5,
        "importPath": "all_stats",
        "description": "all_stats",
        "peekOfCode": "base_folder = os.path.join(project_root)\noutput_base_folder = r\"C:\\Users\\Vadym\\Documents\\magisterka\\output3\"\n# Typy folderów do przetworzenia\nfolder_types = ['classic', 'few_shot', 'one_shot']\nfolders = [f\"results_{i}_{ft}\" for ft in folder_types for i in range(1, 4)]\n# Wzorce uruchamiania\nruns_standard = [i for i in range(2, 17) if i != 12]  # Standardowe uruchomienia (2-16, bez 12)\nruns_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Uruchomienia 1-1 do 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Warianty uruchomienia 12\nruns_highlight = [17, 18, 19, 20, 21]  # Uruchomienia do wyróżnienia",
        "detail": "all_stats",
        "documentation": {}
    },
    {
        "label": "output_base_folder",
        "kind": 5,
        "importPath": "all_stats",
        "description": "all_stats",
        "peekOfCode": "output_base_folder = r\"C:\\Users\\Vadym\\Documents\\magisterka\\output3\"\n# Typy folderów do przetworzenia\nfolder_types = ['classic', 'few_shot', 'one_shot']\nfolders = [f\"results_{i}_{ft}\" for ft in folder_types for i in range(1, 4)]\n# Wzorce uruchamiania\nruns_standard = [i for i in range(2, 17) if i != 12]  # Standardowe uruchomienia (2-16, bez 12)\nruns_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Uruchomienia 1-1 do 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Warianty uruchomienia 12\nruns_highlight = [17, 18, 19, 20, 21]  # Uruchomienia do wyróżnienia\n# Kolumny do wczytania",
        "detail": "all_stats",
        "documentation": {}
    },
    {
        "label": "folder_types",
        "kind": 5,
        "importPath": "all_stats",
        "description": "all_stats",
        "peekOfCode": "folder_types = ['classic', 'few_shot', 'one_shot']\nfolders = [f\"results_{i}_{ft}\" for ft in folder_types for i in range(1, 4)]\n# Wzorce uruchamiania\nruns_standard = [i for i in range(2, 17) if i != 12]  # Standardowe uruchomienia (2-16, bez 12)\nruns_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Uruchomienia 1-1 do 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Warianty uruchomienia 12\nruns_highlight = [17, 18, 19, 20, 21]  # Uruchomienia do wyróżnienia\n# Kolumny do wczytania\ncolumns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",",
        "detail": "all_stats",
        "documentation": {}
    },
    {
        "label": "folders",
        "kind": 5,
        "importPath": "all_stats",
        "description": "all_stats",
        "peekOfCode": "folders = [f\"results_{i}_{ft}\" for ft in folder_types for i in range(1, 4)]\n# Wzorce uruchamiania\nruns_standard = [i for i in range(2, 17) if i != 12]  # Standardowe uruchomienia (2-16, bez 12)\nruns_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Uruchomienia 1-1 do 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Warianty uruchomienia 12\nruns_highlight = [17, 18, 19, 20, 21]  # Uruchomienia do wyróżnienia\n# Kolumny do wczytania\ncolumns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\"",
        "detail": "all_stats",
        "documentation": {}
    },
    {
        "label": "runs_standard",
        "kind": 5,
        "importPath": "all_stats",
        "description": "all_stats",
        "peekOfCode": "runs_standard = [i for i in range(2, 17) if i != 12]  # Standardowe uruchomienia (2-16, bez 12)\nruns_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Uruchomienia 1-1 do 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Warianty uruchomienia 12\nruns_highlight = [17, 18, 19, 20, 21]  # Uruchomienia do wyróżnienia\n# Kolumny do wczytania\ncolumns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\"\n]\n# Lista do przechowywania wyników",
        "detail": "all_stats",
        "documentation": {}
    },
    {
        "label": "runs_1_x",
        "kind": 5,
        "importPath": "all_stats",
        "description": "all_stats",
        "peekOfCode": "runs_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Uruchomienia 1-1 do 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Warianty uruchomienia 12\nruns_highlight = [17, 18, 19, 20, 21]  # Uruchomienia do wyróżnienia\n# Kolumny do wczytania\ncolumns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\"\n]\n# Lista do przechowywania wyników\nall_results = []",
        "detail": "all_stats",
        "documentation": {}
    },
    {
        "label": "run12_variants",
        "kind": 5,
        "importPath": "all_stats",
        "description": "all_stats",
        "peekOfCode": "run12_variants = [\"12-catboost\", \"12-rf\"]  # Warianty uruchomienia 12\nruns_highlight = [17, 18, 19, 20, 21]  # Uruchomienia do wyróżnienia\n# Kolumny do wczytania\ncolumns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\"\n]\n# Lista do przechowywania wyników\nall_results = []\nfor folder in folders:",
        "detail": "all_stats",
        "documentation": {}
    },
    {
        "label": "runs_highlight",
        "kind": 5,
        "importPath": "all_stats",
        "description": "all_stats",
        "peekOfCode": "runs_highlight = [17, 18, 19, 20, 21]  # Uruchomienia do wyróżnienia\n# Kolumny do wczytania\ncolumns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\"\n]\n# Lista do przechowywania wyników\nall_results = []\nfor folder in folders:\n    folder_path = os.path.join(base_folder, folder) + '\\\\'",
        "detail": "all_stats",
        "documentation": {}
    },
    {
        "label": "columns_to_load",
        "kind": 5,
        "importPath": "all_stats",
        "description": "all_stats",
        "peekOfCode": "columns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\"\n]\n# Lista do przechowywania wyników\nall_results = []\nfor folder in folders:\n    folder_path = os.path.join(base_folder, folder) + '\\\\'\n    # Określenie modelu na podstawie numeru w nazwie folderu\n    model_type = None",
        "detail": "all_stats",
        "documentation": {}
    },
    {
        "label": "all_results",
        "kind": 5,
        "importPath": "all_stats",
        "description": "all_stats",
        "peekOfCode": "all_results = []\nfor folder in folders:\n    folder_path = os.path.join(base_folder, folder) + '\\\\'\n    # Określenie modelu na podstawie numeru w nazwie folderu\n    model_type = None\n    if folder.startswith(\"results_1\"):\n        model_type = \"BERT\"\n    elif folder.startswith(\"results_2\"):\n        model_type = \"RoBERTa\"\n    elif folder.startswith(\"results_3\"):",
        "detail": "all_stats",
        "documentation": {}
    },
    {
        "label": "metrics",
        "kind": 5,
        "importPath": "all_stats",
        "description": "all_stats",
        "peekOfCode": "metrics = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\"\n]\nfor folder_type in folder_types:\n    for dataset in datasets:\n        # Tworzenie folderu dla datasetu i folder_type\n        output_folder = os.path.join(output_base_folder, dataset, folder_type)\n        os.makedirs(output_folder, exist_ok=True)\n        for metric in metrics:",
        "detail": "all_stats",
        "documentation": {}
    },
    {
        "label": "load_and_preprocess_data",
        "kind": 2,
        "importPath": "common",
        "description": "common",
        "peekOfCode": "def load_and_preprocess_data(dataset_input):\n    # Wczytanie zbiorów danych\n    project_root = os.getcwd()\n    # Build paths to the dataset files\n    if dataset_input == \"ISOT\":\n        fake_news_path = os.path.join(project_root, \"datasets\", \"ISOT_dataset\", \"Fake.csv\")\n        true_news_path = os.path.join(project_root, \"datasets\", \"ISOT_dataset\", \"True.csv\")\n    elif dataset_input == \"BuzzFeed\":\n        fake_news_path = os.path.join(project_root, \"datasets\", \"BuzzFeed_dataset\", \"Fake.csv\")\n        true_news_path = os.path.join(project_root, \"datasets\", \"BuzzFeed_dataset\", \"True.csv\")",
        "detail": "common",
        "documentation": {}
    },
    {
        "label": "get_bert_embeddings",
        "kind": 2,
        "importPath": "common",
        "description": "common",
        "peekOfCode": "def get_bert_embeddings(texts, batch_size=32, max_length=128, num_labels=2):\n    # Preprocess texts: convert to strings, handle NaN/None/float values\n    cleaned_texts = []\n    for text in texts:\n        if isinstance(text, (str, bytes)):\n            cleaned_texts.append(text)\n        elif pd.isna(text) or text is None or isinstance(text, (float, int)):\n            cleaned_texts.append(\"\")  # Replace NaN/None/float with empty string\n        else:\n            cleaned_texts.append(str(text))  # Convert other types to string",
        "detail": "common",
        "documentation": {}
    },
    {
        "label": "get_roberta_embeddings",
        "kind": 2,
        "importPath": "common",
        "description": "common",
        "peekOfCode": "def get_roberta_embeddings(texts, batch_size=32, max_length=128, num_labels=2):\n    # Preprocess texts: convert to strings, handle NaN/None/float values\n    cleaned_texts = []\n    for text in texts:\n        if isinstance(text, (str, bytes)):\n            cleaned_texts.append(text)\n        elif pd.isna(text) or text is None or isinstance(text, (float, int)):\n            cleaned_texts.append(\"\")  # Replace NaN/None/float with empty string\n        else:\n            cleaned_texts.append(str(text))  # Convert other types to string",
        "detail": "common",
        "documentation": {}
    },
    {
        "label": "get_transformer_embeddings",
        "kind": 2,
        "importPath": "common",
        "description": "common",
        "peekOfCode": "def get_transformer_embeddings(texts, model_name=\"all-MiniLM-L6-v2\"):\n    model = SentenceTransformer(model_name)\n    # Preprocess texts: convert to strings, handle NaN/None/float values\n    cleaned_texts = []\n    for text in texts:\n        # Skip or convert invalid values to empty string\n        if isinstance(text, (str, bytes)):\n            cleaned_texts.append(text)\n        elif pd.isna(text) or text is None or isinstance(text, (float, int)):\n            cleaned_texts.append(\"\")  # Replace NaN/None/float with empty string",
        "detail": "common",
        "documentation": {}
    },
    {
        "label": "vectorize_data",
        "kind": 2,
        "importPath": "common",
        "description": "common",
        "peekOfCode": "def vectorize_data(X, max_features=5000):\n    # Wejściowe dane tekstowe są przekształcane za pomocą TF-IDF\n    tfidf = TfidfVectorizer(max_features=max_features, stop_words='english', ngram_range=(1, 2))\n    return tfidf.fit_transform(X), tfidf\ndef split_data(X, y, test_size=0.2):\n    # Podział danych na zbiory treningowe i testowe\n    return train_test_split(X, y, test_size=test_size, random_state=42)\ndef split_data_one_shot(X, y):\n    \"\"\"Podział danych na podstawie jednego przykładu na klasę.\"\"\"\n    # Konwersja do Pandas DataFrame/Series w razie potrzeby",
        "detail": "common",
        "documentation": {}
    },
    {
        "label": "split_data",
        "kind": 2,
        "importPath": "common",
        "description": "common",
        "peekOfCode": "def split_data(X, y, test_size=0.2):\n    # Podział danych na zbiory treningowe i testowe\n    return train_test_split(X, y, test_size=test_size, random_state=42)\ndef split_data_one_shot(X, y):\n    \"\"\"Podział danych na podstawie jednego przykładu na klasę.\"\"\"\n    # Konwersja do Pandas DataFrame/Series w razie potrzeby\n    if isinstance(X, np.ndarray):\n        X = pd.DataFrame(X)\n    if isinstance(y, np.ndarray):\n        y = pd.Series(y)",
        "detail": "common",
        "documentation": {}
    },
    {
        "label": "split_data_one_shot",
        "kind": 2,
        "importPath": "common",
        "description": "common",
        "peekOfCode": "def split_data_one_shot(X, y):\n    \"\"\"Podział danych na podstawie jednego przykładu na klasę.\"\"\"\n    # Konwersja do Pandas DataFrame/Series w razie potrzeby\n    if isinstance(X, np.ndarray):\n        X = pd.DataFrame(X)\n    if isinstance(y, np.ndarray):\n        y = pd.Series(y)\n    # Wybór jednego przykładu na klasę\n    X_test = X.groupby(y).apply(lambda group: group.iloc[0]).reset_index(drop=True)\n    y_test = y.groupby(y).first().reset_index(drop=True)",
        "detail": "common",
        "documentation": {}
    },
    {
        "label": "split_data_few_shot",
        "kind": 2,
        "importPath": "common",
        "description": "common",
        "peekOfCode": "def split_data_few_shot(X, y, few_shot_examples=5):\n    \"\"\"Podział danych na podstawie kilku przykładów na klasę.\"\"\"\n    # Konwersja do Pandas DataFrame/Series w razie potrzeby\n    if isinstance(X, np.ndarray):\n        X = pd.DataFrame(X)\n    if isinstance(y, np.ndarray):\n        y = pd.Series(y)\n    # Wybór kilku przykładów na klasę\n    sampled_data = y.groupby(y).apply(lambda group: group.sample(n=min(few_shot_examples, len(group))))\n    test_indices = sampled_data.index.get_level_values(1)",
        "detail": "common",
        "documentation": {}
    },
    {
        "label": "evaluate_model",
        "kind": 2,
        "importPath": "common",
        "description": "common",
        "peekOfCode": "def evaluate_model(model, X_test, y_test, run_type, output_path, start_time, dataset_input, flatten=True):\n    # Metryki walidacji krzyżowej\n    cv_accuracy_mean = None\n    cv_accuracy_std = None\n    try:\n        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n        cv_scores = cross_val_score(model, X_test, y_test, cv=skf, scoring=\"accuracy\")\n        cv_accuracy_mean = cv_scores.mean()\n        cv_accuracy_std = cv_scores.std()\n        print(f\"Wyniki dokładności walidacji krzyżowej: {cv_scores}\")",
        "detail": "common",
        "documentation": {}
    },
    {
        "label": "copy_content",
        "kind": 2,
        "importPath": "fixer",
        "description": "fixer",
        "peekOfCode": "def copy_content(source_path, dest_path):\n    with open(source_path, 'r') as source_file:\n        content = source_file.read()\n    with open(dest_path, 'w') as dest_file:\n        dest_file.write(content)\n# Check and create missing files for each pattern pair\nfor pattern1, pattern2 in file_patterns:\n    for run_num in run_numbers:\n        file1 = pattern1.format(run_num)\n        file2 = pattern2.format(run_num)",
        "detail": "fixer",
        "documentation": {}
    },
    {
        "label": "folder_path",
        "kind": 5,
        "importPath": "fixer",
        "description": "fixer",
        "peekOfCode": "folder_path = input(\"Please enter the folder path: \")\n# Define file patterns and run numbers\nrun_numbers = [i for i in range(2, 21) if i != 12]\nfile_patterns = [\n    (\"run{}_BuzzFeed_pr_curve.csv\", \"run{}_BuzzFeed_results.csv\"),\n    (\"run{}_ISOT_pr_curve.csv\", \"run{}_ISOT_results.csv\"),\n    (\"run{}_WELFake_pr_curve.csv\", \"run{}_WELFake_results.csv\")\n]\n# Function to copy content from an existing file\ndef copy_content(source_path, dest_path):",
        "detail": "fixer",
        "documentation": {}
    },
    {
        "label": "run_numbers",
        "kind": 5,
        "importPath": "fixer",
        "description": "fixer",
        "peekOfCode": "run_numbers = [i for i in range(2, 21) if i != 12]\nfile_patterns = [\n    (\"run{}_BuzzFeed_pr_curve.csv\", \"run{}_BuzzFeed_results.csv\"),\n    (\"run{}_ISOT_pr_curve.csv\", \"run{}_ISOT_results.csv\"),\n    (\"run{}_WELFake_pr_curve.csv\", \"run{}_WELFake_results.csv\")\n]\n# Function to copy content from an existing file\ndef copy_content(source_path, dest_path):\n    with open(source_path, 'r') as source_file:\n        content = source_file.read()",
        "detail": "fixer",
        "documentation": {}
    },
    {
        "label": "file_patterns",
        "kind": 5,
        "importPath": "fixer",
        "description": "fixer",
        "peekOfCode": "file_patterns = [\n    (\"run{}_BuzzFeed_pr_curve.csv\", \"run{}_BuzzFeed_results.csv\"),\n    (\"run{}_ISOT_pr_curve.csv\", \"run{}_ISOT_results.csv\"),\n    (\"run{}_WELFake_pr_curve.csv\", \"run{}_WELFake_results.csv\")\n]\n# Function to copy content from an existing file\ndef copy_content(source_path, dest_path):\n    with open(source_path, 'r') as source_file:\n        content = source_file.read()\n    with open(dest_path, 'w') as dest_file:",
        "detail": "fixer",
        "documentation": {}
    },
    {
        "label": "get_embeddings",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def get_embeddings(option, X, y):\n    \"\"\"\n    Generuje reprezentację kontekstową na podstawie wybranej opcji.\n    \"\"\"\n    if option == \"1\":\n        return get_bert_embeddings(X.tolist())\n    elif option == \"2\":\n        return get_roberta_embeddings(X.tolist())\n    elif option == \"3\":\n        return get_transformer_embeddings(X.tolist())",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "run_method",
        "kind": 2,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "def run_method(method_number, X_train, y_train, X_test, y_test, output_path):\n    \"\"\"Uruchamia wybraną metodę na podstawie numeru.\"\"\"\n    start_time = time.time()\n    if method_number == 1:\n        models, X_test, y_test = metoda1(X_train, y_train, X_test, y_test)\n        for i, model in enumerate(models):\n            run_name = f\"run1-{i + 1}\"  # Unikalna nazwa dla każdego modelu\n            evaluate_model(model, X_test, y_test, run_name, output_path, start_time, dataset_input)\n    elif method_number == 2:\n        model, X_test, y_test = metoda2(X_train, y_train, X_test, y_test)",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "dataset_input",
        "kind": 5,
        "importPath": "main",
        "description": "main",
        "peekOfCode": "dataset_input = \"\"\ndef get_embeddings(option, X, y):\n    \"\"\"\n    Generuje reprezentację kontekstową na podstawie wybranej opcji.\n    \"\"\"\n    if option == \"1\":\n        return get_bert_embeddings(X.tolist())\n    elif option == \"2\":\n        return get_roberta_embeddings(X.tolist())\n    elif option == \"3\":",
        "detail": "main",
        "documentation": {}
    },
    {
        "label": "base_folder_path",
        "kind": 5,
        "importPath": "make_tests",
        "description": "make_tests",
        "peekOfCode": "base_folder_path = r'C:\\Users\\Vadym\\Documents\\magisterka'\noutput_base_dir = os.path.join(base_folder_path, 'statistics')\n# Utworzenie katalogu głównego wyjściowego, jeśli nie istnieje\nos.makedirs(output_base_dir, exist_ok=True)\n# Pliki wyjściowe globalne\nranking_file = os.path.join(output_base_dir, \"auc_pr_ranking.csv\")\n# Etykiety metod z zamianą 'run' na 'metoda'\nmethods = [\n    'metoda1-1', 'metoda1-2', 'metoda1-3', 'metoda1-4', 'metoda1-5', \n    'metoda2', 'metoda3', 'metoda4', 'metoda5', ",
        "detail": "make_tests",
        "documentation": {}
    },
    {
        "label": "output_base_dir",
        "kind": 5,
        "importPath": "make_tests",
        "description": "make_tests",
        "peekOfCode": "output_base_dir = os.path.join(base_folder_path, 'statistics')\n# Utworzenie katalogu głównego wyjściowego, jeśli nie istnieje\nos.makedirs(output_base_dir, exist_ok=True)\n# Pliki wyjściowe globalne\nranking_file = os.path.join(output_base_dir, \"auc_pr_ranking.csv\")\n# Etykiety metod z zamianą 'run' na 'metoda'\nmethods = [\n    'metoda1-1', 'metoda1-2', 'metoda1-3', 'metoda1-4', 'metoda1-5', \n    'metoda2', 'metoda3', 'metoda4', 'metoda5', \n    'metoda6', 'metoda7', 'metoda8', 'metoda9'",
        "detail": "make_tests",
        "documentation": {}
    },
    {
        "label": "ranking_file",
        "kind": 5,
        "importPath": "make_tests",
        "description": "make_tests",
        "peekOfCode": "ranking_file = os.path.join(output_base_dir, \"auc_pr_ranking.csv\")\n# Etykiety metod z zamianą 'run' na 'metoda'\nmethods = [\n    'metoda1-1', 'metoda1-2', 'metoda1-3', 'metoda1-4', 'metoda1-5', \n    'metoda2', 'metoda3', 'metoda4', 'metoda5', \n    'metoda6', 'metoda7', 'metoda8', 'metoda9'\n    'metoda10', 'metoda11', 'metoda12-catboost', 'metoda12-rf', \n    'metoda13', 'metoda14', 'metoda15', 'metoda16', \n    'metoda17', 'metoda18', 'metoda19', 'metoda20', \n]",
        "detail": "make_tests",
        "documentation": {}
    },
    {
        "label": "methods",
        "kind": 5,
        "importPath": "make_tests",
        "description": "make_tests",
        "peekOfCode": "methods = [\n    'metoda1-1', 'metoda1-2', 'metoda1-3', 'metoda1-4', 'metoda1-5', \n    'metoda2', 'metoda3', 'metoda4', 'metoda5', \n    'metoda6', 'metoda7', 'metoda8', 'metoda9'\n    'metoda10', 'metoda11', 'metoda12-catboost', 'metoda12-rf', \n    'metoda13', 'metoda14', 'metoda15', 'metoda16', \n    'metoda17', 'metoda18', 'metoda19', 'metoda20', \n]\n# Iteracja po folderach z danymi\nfolders = [f for f in os.listdir(base_folder_path) if f.startswith('results_')]",
        "detail": "make_tests",
        "documentation": {}
    },
    {
        "label": "folders",
        "kind": 5,
        "importPath": "make_tests",
        "description": "make_tests",
        "peekOfCode": "folders = [f for f in os.listdir(base_folder_path) if f.startswith('results_')]\nall_ranking_data = []\nfor folder in folders:\n    folder_path = os.path.join(base_folder_path, folder)\n    if not os.path.isdir(folder_path):\n        continue\n    # Utworzenie odpowiadającego subfolderu w katalogu statistics\n    folder_output_dir = os.path.join(output_base_dir, folder)\n    os.makedirs(folder_output_dir, exist_ok=True)\n    # Pliki wyjściowe dla danego folderu",
        "detail": "make_tests",
        "documentation": {}
    },
    {
        "label": "all_ranking_data",
        "kind": 5,
        "importPath": "make_tests",
        "description": "make_tests",
        "peekOfCode": "all_ranking_data = []\nfor folder in folders:\n    folder_path = os.path.join(base_folder_path, folder)\n    if not os.path.isdir(folder_path):\n        continue\n    # Utworzenie odpowiadającego subfolderu w katalogu statistics\n    folder_output_dir = os.path.join(output_base_dir, folder)\n    os.makedirs(folder_output_dir, exist_ok=True)\n    # Pliki wyjściowe dla danego folderu\n    combined_results_file = os.path.join(folder_path, \"combined_results.csv\")",
        "detail": "make_tests",
        "documentation": {}
    },
    {
        "label": "calculate_confidence_interval",
        "kind": 2,
        "importPath": "make_tests_average",
        "description": "make_tests_average",
        "peekOfCode": "def calculate_confidence_interval(data, confidence=0.95):\n    n = len(data)\n    if n < 2:\n        return np.nan, np.nan\n    mean = np.mean(data)\n    sem = stats.sem(data)\n    ci = sem * stats.t.ppf((1 + confidence) / 2., n - 1)\n    return mean - ci, mean + ci\n# --- Agregacja Danych Globalnych ---\nprint(\"Rozpoczynanie agregacji danych z wszystkich folderów...\")",
        "detail": "make_tests_average",
        "documentation": {}
    },
    {
        "label": "base_folder_path",
        "kind": 5,
        "importPath": "make_tests_average",
        "description": "make_tests_average",
        "peekOfCode": "base_folder_path = r'C:\\Users\\Vadym\\Documents\\magisterka' # Zmień na swoją ścieżkę\noutput_base_dir = os.path.join(base_folder_path, 'statistics_global_by_dataset')\nos.makedirs(output_base_dir, exist_ok=True)\n# Pliki wyjściowe globalne\nranking_file_global = os.path.join(output_base_dir, \"auc_pr_ranking_global_overall.csv\")\n# Etykiety metod z zamianą 'run' na 'metoda'\nmethods = [\n    'metoda1-1', 'metoda1-2', 'metoda1-3', 'metoda1-4', 'metoda1-5',\n    'metoda10', 'metoda11', 'metoda12-catboost', 'metoda12-rf',\n    'metoda13', 'metoda14', 'metoda15', 'metoda16',",
        "detail": "make_tests_average",
        "documentation": {}
    },
    {
        "label": "output_base_dir",
        "kind": 5,
        "importPath": "make_tests_average",
        "description": "make_tests_average",
        "peekOfCode": "output_base_dir = os.path.join(base_folder_path, 'statistics_global_by_dataset')\nos.makedirs(output_base_dir, exist_ok=True)\n# Pliki wyjściowe globalne\nranking_file_global = os.path.join(output_base_dir, \"auc_pr_ranking_global_overall.csv\")\n# Etykiety metod z zamianą 'run' na 'metoda'\nmethods = [\n    'metoda1-1', 'metoda1-2', 'metoda1-3', 'metoda1-4', 'metoda1-5',\n    'metoda10', 'metoda11', 'metoda12-catboost', 'metoda12-rf',\n    'metoda13', 'metoda14', 'metoda15', 'metoda16',\n    'metoda17', 'metoda18', 'metoda19', 'metoda20',",
        "detail": "make_tests_average",
        "documentation": {}
    },
    {
        "label": "ranking_file_global",
        "kind": 5,
        "importPath": "make_tests_average",
        "description": "make_tests_average",
        "peekOfCode": "ranking_file_global = os.path.join(output_base_dir, \"auc_pr_ranking_global_overall.csv\")\n# Etykiety metod z zamianą 'run' na 'metoda'\nmethods = [\n    'metoda1-1', 'metoda1-2', 'metoda1-3', 'metoda1-4', 'metoda1-5',\n    'metoda10', 'metoda11', 'metoda12-catboost', 'metoda12-rf',\n    'metoda13', 'metoda14', 'metoda15', 'metoda16',\n    'metoda17', 'metoda18', 'metoda19', 'metoda20',\n    'metoda2', 'metoda3', 'metoda4', 'metoda5',\n    'metoda6', 'metoda7', 'metoda8', 'metoda9'\n]",
        "detail": "make_tests_average",
        "documentation": {}
    },
    {
        "label": "methods",
        "kind": 5,
        "importPath": "make_tests_average",
        "description": "make_tests_average",
        "peekOfCode": "methods = [\n    'metoda1-1', 'metoda1-2', 'metoda1-3', 'metoda1-4', 'metoda1-5',\n    'metoda10', 'metoda11', 'metoda12-catboost', 'metoda12-rf',\n    'metoda13', 'metoda14', 'metoda15', 'metoda16',\n    'metoda17', 'metoda18', 'metoda19', 'metoda20',\n    'metoda2', 'metoda3', 'metoda4', 'metoda5',\n    'metoda6', 'metoda7', 'metoda8', 'metoda9'\n]\n# Funkcja do obliczania przedziału ufności\ndef calculate_confidence_interval(data, confidence=0.95):",
        "detail": "make_tests_average",
        "documentation": {}
    },
    {
        "label": "all_raw_data_global",
        "kind": 5,
        "importPath": "make_tests_average",
        "description": "make_tests_average",
        "peekOfCode": "all_raw_data_global = []\nall_pr_raw_data_global = []\n# Słownik do przechowywania informacji o pochodzeniu plików (dla debugowania)\nfile_origin = {}\n# Iteracja po wszystkich podfolderach w base_folder_path\nfor root, dirs, files in os.walk(base_folder_path):\n    # Pominięcie folderu wyjściowego\n    if root.startswith(output_base_dir):\n        continue\n    for file in files:",
        "detail": "make_tests_average",
        "documentation": {}
    },
    {
        "label": "all_pr_raw_data_global",
        "kind": 5,
        "importPath": "make_tests_average",
        "description": "make_tests_average",
        "peekOfCode": "all_pr_raw_data_global = []\n# Słownik do przechowywania informacji o pochodzeniu plików (dla debugowania)\nfile_origin = {}\n# Iteracja po wszystkich podfolderach w base_folder_path\nfor root, dirs, files in os.walk(base_folder_path):\n    # Pominięcie folderu wyjściowego\n    if root.startswith(output_base_dir):\n        continue\n    for file in files:\n        file_path = os.path.join(root, file)",
        "detail": "make_tests_average",
        "documentation": {}
    },
    {
        "label": "file_origin",
        "kind": 5,
        "importPath": "make_tests_average",
        "description": "make_tests_average",
        "peekOfCode": "file_origin = {}\n# Iteracja po wszystkich podfolderach w base_folder_path\nfor root, dirs, files in os.walk(base_folder_path):\n    # Pominięcie folderu wyjściowego\n    if root.startswith(output_base_dir):\n        continue\n    for file in files:\n        file_path = os.path.join(root, file)\n        dataset = None\n        if 'BuzzFeed' in file: dataset = 'BuzzFeed'",
        "detail": "make_tests_average",
        "documentation": {}
    },
    {
        "label": "combined_raw_data",
        "kind": 5,
        "importPath": "make_tests_average",
        "description": "make_tests_average",
        "peekOfCode": "combined_raw_data = pd.concat(all_raw_data_global, ignore_index=True) if all_raw_data_global else pd.DataFrame()\npr_raw_data = pd.DataFrame(all_pr_raw_data_global) if all_pr_raw_data_global else pd.DataFrame()\n# Uśrednienie wyników dla każdej metryki (oprócz AUC-PR, które jest oddzielnie)\n# Połączenie 'combined_raw_data' i 'pr_raw_data' na podstawie 'method', 'dataset', 'source_folder'\n# Najpierw upewniamy się, że kolumny do połączenia są obecne\nif 'method' in combined_raw_data.columns and 'dataset' in combined_raw_data.columns and 'source_folder' in combined_raw_data.columns and \\\n   'method' in pr_raw_data.columns and 'dataset' in pr_raw_data.columns and 'source_folder' in pr_raw_data.columns:\n    # Wybieramy numeryczne kolumny z combined_raw_data, usuwając kolumny pomocnicze\n    numeric_cols_results = combined_raw_data.select_dtypes(include=[np.number]).columns.tolist()\n    # Usuwamy kolumny, które nie są metrykami, ale mogą być numeryczne (np. 'unnamed: 0')",
        "detail": "make_tests_average",
        "documentation": {}
    },
    {
        "label": "pr_raw_data",
        "kind": 5,
        "importPath": "make_tests_average",
        "description": "make_tests_average",
        "peekOfCode": "pr_raw_data = pd.DataFrame(all_pr_raw_data_global) if all_pr_raw_data_global else pd.DataFrame()\n# Uśrednienie wyników dla każdej metryki (oprócz AUC-PR, które jest oddzielnie)\n# Połączenie 'combined_raw_data' i 'pr_raw_data' na podstawie 'method', 'dataset', 'source_folder'\n# Najpierw upewniamy się, że kolumny do połączenia są obecne\nif 'method' in combined_raw_data.columns and 'dataset' in combined_raw_data.columns and 'source_folder' in combined_raw_data.columns and \\\n   'method' in pr_raw_data.columns and 'dataset' in pr_raw_data.columns and 'source_folder' in pr_raw_data.columns:\n    # Wybieramy numeryczne kolumny z combined_raw_data, usuwając kolumny pomocnicze\n    numeric_cols_results = combined_raw_data.select_dtypes(include=[np.number]).columns.tolist()\n    # Usuwamy kolumny, które nie są metrykami, ale mogą być numeryczne (np. 'unnamed: 0')\n    metrics_to_consider_results = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC', 'MCC', \"Cohen's Kappa\"]",
        "detail": "make_tests_average",
        "documentation": {}
    },
    {
        "label": "datasets",
        "kind": 5,
        "importPath": "make_tests_average",
        "description": "make_tests_average",
        "peekOfCode": "datasets = full_aggregated_data['dataset'].unique()\nall_global_ranking_data = [] # Do globalnego rankingu AUC-PR\nfor dataset in datasets:\n    print(f\"\\nRozpoczynanie analizy dla datasetu: {dataset}\")\n    dataset_output_dir = os.path.join(output_base_dir, dataset)\n    os.makedirs(dataset_output_dir, exist_ok=True)\n    # Dane dla bieżącego datasetu (używamy pełnych zagregowanych danych, które zawierają wyniki z różnych source_folder)\n    current_dataset_aggregated_data = full_aggregated_data[full_aggregated_data['dataset'] == dataset].copy()\n    # Pełne surowe dane dla boxplotów i histogramów (jeśli potrzebne, z oryginalnych ram danych)\n    # Filter raw data for the current dataset",
        "detail": "make_tests_average",
        "documentation": {}
    },
    {
        "label": "all_global_ranking_data",
        "kind": 5,
        "importPath": "make_tests_average",
        "description": "make_tests_average",
        "peekOfCode": "all_global_ranking_data = [] # Do globalnego rankingu AUC-PR\nfor dataset in datasets:\n    print(f\"\\nRozpoczynanie analizy dla datasetu: {dataset}\")\n    dataset_output_dir = os.path.join(output_base_dir, dataset)\n    os.makedirs(dataset_output_dir, exist_ok=True)\n    # Dane dla bieżącego datasetu (używamy pełnych zagregowanych danych, które zawierają wyniki z różnych source_folder)\n    current_dataset_aggregated_data = full_aggregated_data[full_aggregated_data['dataset'] == dataset].copy()\n    # Pełne surowe dane dla boxplotów i histogramów (jeśli potrzebne, z oryginalnych ram danych)\n    # Filter raw data for the current dataset\n    raw_data_for_boxplot = combined_raw_data[combined_raw_data['dataset'] == dataset].copy()",
        "detail": "make_tests_average",
        "documentation": {}
    },
    {
        "label": "metoda17",
        "kind": 2,
        "importPath": "my_run",
        "description": "my_run",
        "peekOfCode": "def metoda17(X_train, y_train, X_test, y_test):\n    \"\"\"\n    Trenuje ulepszony model zespołowy z miękkim głosowaniem (soft-voting) z optymalizacją\n    hiperparametrów i skalowaniem cech.\n    Parametry:\n        X_train (np.ndarray): Cechy zbioru treningowego.\n        y_train (lista lub np.ndarray): Etykiety zbioru treningowego.\n        X_test (np.ndarray): Cechy zbioru testowego.\n        y_test (lista lub np.ndarray): Etykiety zbioru testowego.\n    Zwraca:",
        "detail": "my_run",
        "documentation": {}
    },
    {
        "label": "metoda18",
        "kind": 2,
        "importPath": "my_run",
        "description": "my_run",
        "peekOfCode": "def metoda18(X_train, y_train, X_test, y_test):\n    \"\"\"\n    Trenuje klasyfikatory GradientBoosting i CatBoost oraz łączy ich predykcje przy użyciu meta-modelu.\n    \"\"\"\n    gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)  # Gradient Boosting\n    cat_clf = CatBoostClassifier(iterations=100, verbose=0, random_state=42)  # CatBoost\n    gb_clf.fit(X_train, y_train)\n    cat_clf.fit(X_train, y_train)\n    gb_preds_train = gb_clf.predict_proba(X_train)[:, 1]  # Predykcje treningowe dla GradientBoosting\n    cat_preds_train = cat_clf.predict_proba(X_train)[:, 1]  # Predykcje treningowe dla CatBoost",
        "detail": "my_run",
        "documentation": {}
    },
    {
        "label": "metoda19",
        "kind": 2,
        "importPath": "my_run",
        "description": "my_run",
        "peekOfCode": "def metoda19(X_train, y_train, X_test, y_test):\n    \"\"\"\n    Ulepszony model stacking z Random Forest, XGBoost i GradientBoosting jako bazowymi oraz Logistic Regression jako meta-modelem.\n    Parametry:\n        X_train (array-like): Cechy zbioru treningowego.\n        y_train (array-like): Etykiety zbioru treningowego.\n        X_test (array-like): Cechy zbioru testowego.\n        y_test (array-like): Etykiety zbioru testowego.\n    Zwraca:\n        meta_model: Wytrenowany model meta (Logistic Regression).",
        "detail": "my_run",
        "documentation": {}
    },
    {
        "label": "metoda20",
        "kind": 2,
        "importPath": "my_run",
        "description": "my_run",
        "peekOfCode": "def metoda20(X_train, y_train, X_test, y_test):\n    \"\"\"\n    Trenuje klasyfikatory LightGBM, CatBoost, Random Forest i Gradient Boosting\n    oraz łączy ich predykcje przy użyciu meta-modelu (regresji logistycznej).\n    \"\"\"\n    lgb_clf = LGBMClassifier(n_estimators=100, random_state=42)  # LightGBM\n    cat_clf = CatBoostClassifier(iterations=100, verbose=0, random_state=42)  # CatBoost\n    rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)  # Random Forest\n    gb_clf = GradientBoostingClassifier(n_estimators=100, random_state=42)  # Gradient Boosting\n    lgb_clf.fit(X_train, y_train)",
        "detail": "my_run",
        "documentation": {}
    },
    {
        "label": "remove_outliers",
        "kind": 2,
        "importPath": "plots_best",
        "description": "plots_best",
        "peekOfCode": "def remove_outliers(data, column):\n    \"\"\"\n    Removes values that are far beyond the interquartile range (IQR).\n    \"\"\"\n    Q1 = data[column].quantile(0.25)  # First quartile (25th percentile)\n    Q3 = data[column].quantile(0.75)  # Third quartile (75th percentile)\n    IQR = Q3 - Q1  # Interquartile range\n    lower_bound = Q1 - 1.5 * IQR  # Lower bound\n    upper_bound = Q3 + 1.5 * IQR  # Upper bound\n    return data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]",
        "detail": "plots_best",
        "documentation": {}
    },
    {
        "label": "project_root",
        "kind": 5,
        "importPath": "plots_best",
        "description": "plots_best",
        "peekOfCode": "project_root = os.getcwd()\nbase_folder = os.path.join(project_root)\nplot_base_folder = os.path.join(project_root, \"plots\")\n# Define folder to process\nfolder = \"results_3_few_shot\"\nfolder_path = os.path.join(base_folder, folder) + '\\\\'\nplots_output_path = os.path.join(plot_base_folder, folder) + '\\\\'\nos.makedirs(plots_output_path, exist_ok=True)  # Creates main folder if it doesn't exist\n# Create ISOT-specific subfolder for plots\ndataset = 'ISOT'",
        "detail": "plots_best",
        "documentation": {}
    },
    {
        "label": "base_folder",
        "kind": 5,
        "importPath": "plots_best",
        "description": "plots_best",
        "peekOfCode": "base_folder = os.path.join(project_root)\nplot_base_folder = os.path.join(project_root, \"plots\")\n# Define folder to process\nfolder = \"results_3_few_shot\"\nfolder_path = os.path.join(base_folder, folder) + '\\\\'\nplots_output_path = os.path.join(plot_base_folder, folder) + '\\\\'\nos.makedirs(plots_output_path, exist_ok=True)  # Creates main folder if it doesn't exist\n# Create ISOT-specific subfolder for plots\ndataset = 'ISOT'\ndataset_plot_path = os.path.join(plots_output_path, dataset)",
        "detail": "plots_best",
        "documentation": {}
    },
    {
        "label": "plot_base_folder",
        "kind": 5,
        "importPath": "plots_best",
        "description": "plots_best",
        "peekOfCode": "plot_base_folder = os.path.join(project_root, \"plots\")\n# Define folder to process\nfolder = \"results_3_few_shot\"\nfolder_path = os.path.join(base_folder, folder) + '\\\\'\nplots_output_path = os.path.join(plot_base_folder, folder) + '\\\\'\nos.makedirs(plots_output_path, exist_ok=True)  # Creates main folder if it doesn't exist\n# Create ISOT-specific subfolder for plots\ndataset = 'ISOT'\ndataset_plot_path = os.path.join(plots_output_path, dataset)\nos.makedirs(dataset_plot_path, exist_ok=True)",
        "detail": "plots_best",
        "documentation": {}
    },
    {
        "label": "folder",
        "kind": 5,
        "importPath": "plots_best",
        "description": "plots_best",
        "peekOfCode": "folder = \"results_3_few_shot\"\nfolder_path = os.path.join(base_folder, folder) + '\\\\'\nplots_output_path = os.path.join(plot_base_folder, folder) + '\\\\'\nos.makedirs(plots_output_path, exist_ok=True)  # Creates main folder if it doesn't exist\n# Create ISOT-specific subfolder for plots\ndataset = 'ISOT'\ndataset_plot_path = os.path.join(plots_output_path, dataset)\nos.makedirs(dataset_plot_path, exist_ok=True)\n# Define run patterns\nruns = [i for i in range(1, 17)]  # Runs 1 to 16",
        "detail": "plots_best",
        "documentation": {}
    },
    {
        "label": "folder_path",
        "kind": 5,
        "importPath": "plots_best",
        "description": "plots_best",
        "peekOfCode": "folder_path = os.path.join(base_folder, folder) + '\\\\'\nplots_output_path = os.path.join(plot_base_folder, folder) + '\\\\'\nos.makedirs(plots_output_path, exist_ok=True)  # Creates main folder if it doesn't exist\n# Create ISOT-specific subfolder for plots\ndataset = 'ISOT'\ndataset_plot_path = os.path.join(plots_output_path, dataset)\nos.makedirs(dataset_plot_path, exist_ok=True)\n# Define run patterns\nruns = [i for i in range(1, 17)]  # Runs 1 to 16\nruns_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Runs 1-1 to 1-5",
        "detail": "plots_best",
        "documentation": {}
    },
    {
        "label": "plots_output_path",
        "kind": 5,
        "importPath": "plots_best",
        "description": "plots_best",
        "peekOfCode": "plots_output_path = os.path.join(plot_base_folder, folder) + '\\\\'\nos.makedirs(plots_output_path, exist_ok=True)  # Creates main folder if it doesn't exist\n# Create ISOT-specific subfolder for plots\ndataset = 'ISOT'\ndataset_plot_path = os.path.join(plots_output_path, dataset)\nos.makedirs(dataset_plot_path, exist_ok=True)\n# Define run patterns\nruns = [i for i in range(1, 17)]  # Runs 1 to 16\nruns_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Runs 1-1 to 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Run 12 variants",
        "detail": "plots_best",
        "documentation": {}
    },
    {
        "label": "dataset",
        "kind": 5,
        "importPath": "plots_best",
        "description": "plots_best",
        "peekOfCode": "dataset = 'ISOT'\ndataset_plot_path = os.path.join(plots_output_path, dataset)\nos.makedirs(dataset_plot_path, exist_ok=True)\n# Define run patterns\nruns = [i for i in range(1, 17)]  # Runs 1 to 16\nruns_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Runs 1-1 to 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Run 12 variants\n# Updated columns to load\ncolumns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",",
        "detail": "plots_best",
        "documentation": {}
    },
    {
        "label": "dataset_plot_path",
        "kind": 5,
        "importPath": "plots_best",
        "description": "plots_best",
        "peekOfCode": "dataset_plot_path = os.path.join(plots_output_path, dataset)\nos.makedirs(dataset_plot_path, exist_ok=True)\n# Define run patterns\nruns = [i for i in range(1, 17)]  # Runs 1 to 16\nruns_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Runs 1-1 to 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Run 12 variants\n# Updated columns to load\ncolumns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\", \"CV Accuracy (Std Dev)\"",
        "detail": "plots_best",
        "documentation": {}
    },
    {
        "label": "runs",
        "kind": 5,
        "importPath": "plots_best",
        "description": "plots_best",
        "peekOfCode": "runs = [i for i in range(1, 17)]  # Runs 1 to 16\nruns_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Runs 1-1 to 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Run 12 variants\n# Updated columns to load\ncolumns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\", \"CV Accuracy (Std Dev)\"\n]\n# Create file paths for ISOT dataset and run patterns\nresults_files = []",
        "detail": "plots_best",
        "documentation": {}
    },
    {
        "label": "runs_1_x",
        "kind": 5,
        "importPath": "plots_best",
        "description": "plots_best",
        "peekOfCode": "runs_1_x = [f\"1-{i}\" for i in range(1, 6)]  # Runs 1-1 to 1-5\nrun12_variants = [\"12-catboost\", \"12-rf\"]  # Run 12 variants\n# Updated columns to load\ncolumns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\", \"CV Accuracy (Std Dev)\"\n]\n# Create file paths for ISOT dataset and run patterns\nresults_files = []\npr_curve_files = []",
        "detail": "plots_best",
        "documentation": {}
    },
    {
        "label": "run12_variants",
        "kind": 5,
        "importPath": "plots_best",
        "description": "plots_best",
        "peekOfCode": "run12_variants = [\"12-catboost\", \"12-rf\"]  # Run 12 variants\n# Updated columns to load\ncolumns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\", \"CV Accuracy (Std Dev)\"\n]\n# Create file paths for ISOT dataset and run patterns\nresults_files = []\npr_curve_files = []\nfor run in runs:",
        "detail": "plots_best",
        "documentation": {}
    },
    {
        "label": "columns_to_load",
        "kind": 5,
        "importPath": "plots_best",
        "description": "plots_best",
        "peekOfCode": "columns_to_load = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\", \"CV Accuracy (Std Dev)\"\n]\n# Create file paths for ISOT dataset and run patterns\nresults_files = []\npr_curve_files = []\nfor run in runs:\n    results_files.append(f\"{folder_path}run{run}_{dataset}_results.csv\")\n    pr_curve_files.append(f\"{folder_path}run{run}_{dataset}_pr_curve.csv\")",
        "detail": "plots_best",
        "documentation": {}
    },
    {
        "label": "results_files",
        "kind": 5,
        "importPath": "plots_best",
        "description": "plots_best",
        "peekOfCode": "results_files = []\npr_curve_files = []\nfor run in runs:\n    results_files.append(f\"{folder_path}run{run}_{dataset}_results.csv\")\n    pr_curve_files.append(f\"{folder_path}run{run}_{dataset}_pr_curve.csv\")\nfor run in runs_1_x:\n    results_files.append(f\"{folder_path}run{run}_{dataset}_results.csv\")\n    pr_curve_files.append(f\"{folder_path}run{run}_{dataset}_pr_curve.csv\")\nfor run in run12_variants:\n    results_files.append(f\"{folder_path}run{run}_{dataset}_results.csv\")",
        "detail": "plots_best",
        "documentation": {}
    },
    {
        "label": "pr_curve_files",
        "kind": 5,
        "importPath": "plots_best",
        "description": "plots_best",
        "peekOfCode": "pr_curve_files = []\nfor run in runs:\n    results_files.append(f\"{folder_path}run{run}_{dataset}_results.csv\")\n    pr_curve_files.append(f\"{folder_path}run{run}_{dataset}_pr_curve.csv\")\nfor run in runs_1_x:\n    results_files.append(f\"{folder_path}run{run}_{dataset}_results.csv\")\n    pr_curve_files.append(f\"{folder_path}run{run}_{dataset}_pr_curve.csv\")\nfor run in run12_variants:\n    results_files.append(f\"{folder_path}run{run}_{dataset}_results.csv\")\n    pr_curve_files.append(f\"{folder_path}run{run}_{dataset}_pr_curve.csv\")",
        "detail": "plots_best",
        "documentation": {}
    },
    {
        "label": "results_data",
        "kind": 5,
        "importPath": "plots_best",
        "description": "plots_best",
        "peekOfCode": "results_data = []\nfor file in results_files:\n    if os.path.exists(file):  # Check if file exists\n        try:\n            data = pd.read_csv(file, usecols=lambda col: col in columns_to_load + ['Metoda'])\n            # Extract method name with run number\n            run_name = os.path.basename(file).replace(\"run\", \"metoda\").split('_')[0]  # Remove \"run\" prefix\n            dataset_name = os.path.basename(file).split('_')[1]  # Extract dataset name\n            data['Metoda'] = f\"{run_name}_{dataset_name}\"  # Add column with method and dataset\n            results_data.append(data)",
        "detail": "plots_best",
        "documentation": {}
    },
    {
        "label": "pr_curves",
        "kind": 5,
        "importPath": "plots_best",
        "description": "plots_best",
        "peekOfCode": "pr_curves = {}\nfor file in pr_curve_files:\n    if os.path.exists(file):  # Check if file exists\n        try:\n            run_name = os.path.basename(file).replace(\"run\", \"metoda\").split('_')[0]  # Remove \"run\" prefix\n            dataset_name = os.path.basename(file).split('_')[1]  # Extract dataset name\n            pr_curves[f\"{run_name}_{dataset_name}\"] = pd.read_csv(file)\n        except Exception as e:\n            print(f\"Error reading {file}: {e}\")\n# Create comparative plots for each metric for ISOT",
        "detail": "plots_best",
        "documentation": {}
    },
    {
        "label": "metrics",
        "kind": 5,
        "importPath": "plots_best",
        "description": "plots_best",
        "peekOfCode": "metrics = [\n    \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"ROC-AUC\", \"MCC\",\n    \"Log Loss\", \"Cohen's Kappa\", \"Execution Time (s)\", \"CV Accuracy (Mean)\", \"CV Accuracy (Std Dev)\"\n]\nif not all_results.empty:\n    for metric in metrics:\n        if metric in all_results.columns:\n            # Check if column is not empty and not all values are None or 0\n            if all_results[metric].notna().any() and all_results[metric].sum() != 0:\n                mask = (all_results[metric] != 0) & (all_results[metric] != 0.0) & (all_results[metric].notna())",
        "detail": "plots_best",
        "documentation": {}
    },
    {
        "label": "source_base",
        "kind": 5,
        "importPath": "unite_plots",
        "description": "unite_plots",
        "peekOfCode": "source_base = r\"C:\\Users\\Vadym\\Documents\\magisterka\\plots\"\noutput_base = r\"C:\\Users\\Vadym\\Documents\\magisterka\\output2\"\n# Ustawienia\ndatasets = [\"BuzzFeed\", \"ISOT\", \"WELFake\"]\nmethods = [\"classic\", \"few_shot\", \"one_shot\"]\nresults_folders = [\"results_1\", \"results_2\", \"results_3\"]\n# Lista wszystkich typów obrazów do przetworzenia, z pełnymi nazwami plików\nimage_types = [\n    \"Accuracy_comparison.png\",\n    \"Execution Time (s)_comparison.png\",",
        "detail": "unite_plots",
        "documentation": {}
    },
    {
        "label": "output_base",
        "kind": 5,
        "importPath": "unite_plots",
        "description": "unite_plots",
        "peekOfCode": "output_base = r\"C:\\Users\\Vadym\\Documents\\magisterka\\output2\"\n# Ustawienia\ndatasets = [\"BuzzFeed\", \"ISOT\", \"WELFake\"]\nmethods = [\"classic\", \"few_shot\", \"one_shot\"]\nresults_folders = [\"results_1\", \"results_2\", \"results_3\"]\n# Lista wszystkich typów obrazów do przetworzenia, z pełnymi nazwami plików\nimage_types = [\n    \"Accuracy_comparison.png\",\n    \"Execution Time (s)_comparison.png\",\n    \"F1-Score_comparison.png\",",
        "detail": "unite_plots",
        "documentation": {}
    },
    {
        "label": "datasets",
        "kind": 5,
        "importPath": "unite_plots",
        "description": "unite_plots",
        "peekOfCode": "datasets = [\"BuzzFeed\", \"ISOT\", \"WELFake\"]\nmethods = [\"classic\", \"few_shot\", \"one_shot\"]\nresults_folders = [\"results_1\", \"results_2\", \"results_3\"]\n# Lista wszystkich typów obrazów do przetworzenia, z pełnymi nazwami plików\nimage_types = [\n    \"Accuracy_comparison.png\",\n    \"Execution Time (s)_comparison.png\",\n    \"F1-Score_comparison.png\",\n    \"MCC_comparison.png\",\n    \"Precision_comparison.png\",",
        "detail": "unite_plots",
        "documentation": {}
    },
    {
        "label": "methods",
        "kind": 5,
        "importPath": "unite_plots",
        "description": "unite_plots",
        "peekOfCode": "methods = [\"classic\", \"few_shot\", \"one_shot\"]\nresults_folders = [\"results_1\", \"results_2\", \"results_3\"]\n# Lista wszystkich typów obrazów do przetworzenia, z pełnymi nazwami plików\nimage_types = [\n    \"Accuracy_comparison.png\",\n    \"Execution Time (s)_comparison.png\",\n    \"F1-Score_comparison.png\",\n    \"MCC_comparison.png\",\n    \"Precision_comparison.png\",\n    \"Recall_comparison.png\",",
        "detail": "unite_plots",
        "documentation": {}
    },
    {
        "label": "results_folders",
        "kind": 5,
        "importPath": "unite_plots",
        "description": "unite_plots",
        "peekOfCode": "results_folders = [\"results_1\", \"results_2\", \"results_3\"]\n# Lista wszystkich typów obrazów do przetworzenia, z pełnymi nazwami plików\nimage_types = [\n    \"Accuracy_comparison.png\",\n    \"Execution Time (s)_comparison.png\",\n    \"F1-Score_comparison.png\",\n    \"MCC_comparison.png\",\n    \"Precision_comparison.png\",\n    \"Recall_comparison.png\",\n    \"ROC-AUC_comparison.png\"",
        "detail": "unite_plots",
        "documentation": {}
    },
    {
        "label": "image_types",
        "kind": 5,
        "importPath": "unite_plots",
        "description": "unite_plots",
        "peekOfCode": "image_types = [\n    \"Accuracy_comparison.png\",\n    \"Execution Time (s)_comparison.png\",\n    \"F1-Score_comparison.png\",\n    \"MCC_comparison.png\",\n    \"Precision_comparison.png\",\n    \"Recall_comparison.png\",\n    \"ROC-AUC_comparison.png\"\n]\n# Przetwarzanie",
        "detail": "unite_plots",
        "documentation": {}
    },
    {
        "label": "source_base",
        "kind": 5,
        "importPath": "unite_tests",
        "description": "unite_tests",
        "peekOfCode": "source_base = r\"C:\\Users\\Vadym\\Documents\\magisterka\\statistics\"\noutput_base = r\"C:\\Users\\Vadym\\Documents\\magisterka\\output\"\n# Settings\ndatasets = [\"BuzzFeed\", \"ISOT\", \"WELFake\"]\nmethods = [\"classic\", \"few_shot\", \"one_shot\"]\nresults_folders = [\"results_1\", \"results_2\", \"results_3\"]\n# List of *base names* for the plots you want to combine\n# These should be the parts that are common across results_1, results_2, results_3\nplot_base_names = [\n    \"Accuracy_bar_chart\",",
        "detail": "unite_tests",
        "documentation": {}
    },
    {
        "label": "output_base",
        "kind": 5,
        "importPath": "unite_tests",
        "description": "unite_tests",
        "peekOfCode": "output_base = r\"C:\\Users\\Vadym\\Documents\\magisterka\\output\"\n# Settings\ndatasets = [\"BuzzFeed\", \"ISOT\", \"WELFake\"]\nmethods = [\"classic\", \"few_shot\", \"one_shot\"]\nresults_folders = [\"results_1\", \"results_2\", \"results_3\"]\n# List of *base names* for the plots you want to combine\n# These should be the parts that are common across results_1, results_2, results_3\nplot_base_names = [\n    \"Accuracy_bar_chart\",\n    \"Cohen's Kappa_bar\",",
        "detail": "unite_tests",
        "documentation": {}
    },
    {
        "label": "datasets",
        "kind": 5,
        "importPath": "unite_tests",
        "description": "unite_tests",
        "peekOfCode": "datasets = [\"BuzzFeed\", \"ISOT\", \"WELFake\"]\nmethods = [\"classic\", \"few_shot\", \"one_shot\"]\nresults_folders = [\"results_1\", \"results_2\", \"results_3\"]\n# List of *base names* for the plots you want to combine\n# These should be the parts that are common across results_1, results_2, results_3\nplot_base_names = [\n    \"Accuracy_bar_chart\",\n    \"Cohen's Kappa_bar\",\n    \"F1-Score_bar\",\n    \"MCC_bar_chart\",",
        "detail": "unite_tests",
        "documentation": {}
    },
    {
        "label": "methods",
        "kind": 5,
        "importPath": "unite_tests",
        "description": "unite_tests",
        "peekOfCode": "methods = [\"classic\", \"few_shot\", \"one_shot\"]\nresults_folders = [\"results_1\", \"results_2\", \"results_3\"]\n# List of *base names* for the plots you want to combine\n# These should be the parts that are common across results_1, results_2, results_3\nplot_base_names = [\n    \"Accuracy_bar_chart\",\n    \"Cohen's Kappa_bar\",\n    \"F1-Score_bar\",\n    \"MCC_bar_chart\",\n    \"Precision_bar_chart\",",
        "detail": "unite_tests",
        "documentation": {}
    },
    {
        "label": "results_folders",
        "kind": 5,
        "importPath": "unite_tests",
        "description": "unite_tests",
        "peekOfCode": "results_folders = [\"results_1\", \"results_2\", \"results_3\"]\n# List of *base names* for the plots you want to combine\n# These should be the parts that are common across results_1, results_2, results_3\nplot_base_names = [\n    \"Accuracy_bar_chart\",\n    \"Cohen's Kappa_bar\",\n    \"F1-Score_bar\",\n    \"MCC_bar_chart\",\n    \"Precision_bar_chart\",\n    \"ROC-AUC_bar\",",
        "detail": "unite_tests",
        "documentation": {}
    },
    {
        "label": "plot_base_names",
        "kind": 5,
        "importPath": "unite_tests",
        "description": "unite_tests",
        "peekOfCode": "plot_base_names = [\n    \"Accuracy_bar_chart\",\n    \"Cohen's Kappa_bar\",\n    \"F1-Score_bar\",\n    \"MCC_bar_chart\",\n    \"Precision_bar_chart\",\n    \"ROC-AUC_bar\",\n    \"Recall_bar\",\n    \"boxplot\"\n]",
        "detail": "unite_tests",
        "documentation": {}
    }
]